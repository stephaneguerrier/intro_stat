<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="St√©phane Guerrier &amp; Yuming Zhang" />
    <meta name="date" content="2021-01-08" />
    <link href="lecture2_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="lecture2_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="lecture2_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link href="lecture2_files/tile-view-0.2.4/tile-view.css" rel="stylesheet" />
    <script src="lecture2_files/tile-view-0.2.4/tile-view.js"></script>
    <link href="lecture2_files/panelset-0.2.4/panelset.css" rel="stylesheet" />
    <script src="lecture2_files/panelset-0.2.4/panelset.js"></script>
    <script src="lecture2_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="lecture2_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="lecture2_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to Statistics
## Part II: Introduction to Statistical Inference
### St√©phane Guerrier &amp; Yuming Zhang
### 8 January 2021

---










# Review

- .smallest[.hi-pink[Statistical inference] allows to infer the properties of a population based on an observed sample.]
- .smallest[.hi-purple[Proportion estimation]] `\(\color{#6A5ACD}{\hat{p}}\)` .smallest[is .hi-purple[random] as it is sample dependent. Therefore, we need to access the .hi-purple[uncertainty] of] `\(\hat{p}\)`.
- .smallest[One common approach to measure uncertainty is to use .hi-turquoise[confidence intervals], which rely on .hi-turquoise[Central Limit Theorem]. In the case of proportion estimation, we have] `$$\small \hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(\color{#e64173}{p}, \color{#6A5ACD}{\frac{p(1-p)}{n}}\Bigg).$$`
- .smallest[Confidence intervals correspond to a range of values that are likely to include the population value with .hi-pink[a certain level of confidence]. The] `\(1-\alpha\)` .smallest[confidence interval for] `\(p\)` .smallest[is given by] `\(\color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}\)` .smallest[, and obviously, it is random.]
- .smallest[In Statistics, a decision or prediction can never be made with certainty. There always exists .hi-turquoise[a trade-off between the risk and the precision of the conclusion], and how much risk is acceptable depends on the context.]

---

# How to test a (scientific) hypothesis?

- .smallest[An alternative summary measure of uncertainty is provided  by .hi-pink[p-values] that take values between 0% and 100%.]
- .smallest[However, .hi-purple[p-values have been misused] many times because understanding what they mean is not intuitive.]

&lt;div align="center"&gt;
&lt;iframe src="https://fivethirtyeight.abcnews.go.com/video/embed/56150342" width="512" height="288" scrolling="no" style="border:none;" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt; 

üëã .tiny[If you want to know more have a look [here](https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/).]

---

# A hypothesis testing

- A p-value is associated to (a couple of) .purple[hypotheses] about the phenomenon under investigation, such as
1. Coffee consumption increases blood pressure (really üôÑ ‚òï?)
2. Republican politicians are bad/good for the American Economy.
3. A glass of red wine is as good as an hour at the gym (üç∑ üèÉ üòÜ).

- More precisely, a hypothesis testing is designed to assess the strength of evidence against a baseline hypothesis called .pink[null hypothesis] `\(\color{#e64173}{H_0}\)` and in favor of another hypothesis called .pink[alternative hypothesis] `\(\color{#e64173}{H_a}\)`.

---

# A hypothesis testing

- In the Biden-Trump example, we can write
.center[
`\(H_0: p = 0.5\)` and `\(H_a: p &gt; 0.5\)`.
]
- Each hypothesis .purple[excludes the other], so that one can .purple[exclude one in favor of the other] using the data.
- The .pink[null hypothesis] is the one that one will never be able to prove because the data is random.
- The .pink[alternative hypothesis] is the one that offers more choice of values and hence has a chance to be favored with respect to the null hypothesis.
- If we reject `\(H_0\)` when in fact `\(H_0\)` is true, this is a .purple[Type I error]. If we accept `\(H_0\)` when in fact `\(H_a\)` is true, this is a .purple[Type II error]. 

---

# Test statistic and P-value

- .smallest[A hypothesis testing is based on a .hi-pink[test statistic], which measures the difference between the sample estimate and the hypothesized value in terms of its standard deviation, i.e.] 
`$$\small \text{test statistic} = \frac{\text{sample estimate - hypothesized value}}{\text{standard deviation of sample estimate}}.$$`
- .smallest[For a test for a single proportion, the test statistic is computed as] `$$z = \frac{\hat{p}-\color{#e64173}{p_0}}{\color{#6A5ACD}{\sqrt{\frac{p_0(1-p_0)}{n}}}} \sim \mathcal{N}(0,1).$$`
- .smallest[The .hi-purple[p-value] is defined as the probability, assuming that] `\(\small H_0\)` .smallest[is true, that the test statistic will take a value at least as extreme as that actually observed.] ü§Øüò±
- .smallest[Informally, .pink[a p-value can be understood as a measure of plausibility of the null hypothesis given the data]. Small p-value indicate strong evidence against] `\(\small H_0\)`.

---

# Test statistic and P-value

- .smaller[When the p-value is small enough (typically smaller than 5%), one says that the test based on the null and alternative hypotheses is .hi-pink[significant] or that the null hypothesis is rejected in favor of the alternative. .purple[This is generally what we want because it "verifies" our (research) hypothesis].]
- .smaller[When the p-value is not small enough (typically larger than 5%), with the available data, we cannot reject the null hypothesis and then .hi-pink[nothing] can be concluded. ü§î]
- .smaller[With a sample of data, the obtained p-value (associated to a couple of hypotheses) summarizes somehow the .hi-pink[incompatibility between the data and the model] (random process) constructed under the set of assumptions.]
- .smaller[The p-value is usually compared to a .purple[threshold value] that sets the (subjective) risk level of decision in favor of the incompatibility. The risk level is called the .purple[significance level] and is a small value, usually 5%, but this depends on the context.]

---

# Test for a single proportion: Example 1

.panelset[
.panel[.panel-name[Problem]
.smallest[Returning to our Biden-Trump example, suppose we believe (or hope to show that) .pink[Biden will have more than 50% of the votes]. We collect data with] `\(\small n = 600\)` .smallest[and] `\(\small m = 322\)`.smallest[. We will consider the following steps to set up the test:]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.5\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&gt;} 0.5\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 3.959\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the proportion of voters for Biden is greater than 50%.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 322, n = 600, p = 0.5, alternative = "greater")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  322 out of 600, null probability 0.5
#&gt; X-squared = 3.0817, df = 1, p-value = 0.03959
#&gt; alternative hypothesis: true p is greater than 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.5022582 1.0000000
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5366667
```
]
]

---

# Test for a single proportion: Example 1

.panelset[
.panel[.panel-name[Problem]
.smallest[What if we want to check if .pink[Trump will have more than 50% of the votes]. Using the same data, we set up the test as follows:]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.5\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&lt;} 0.5\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 96.04\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that Trump will have more than 50% of the votes.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 322, n = 600, p = 0.5, alternative = "less")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  322 out of 600, null probability 0.5
#&gt; X-squared = 3.0817, df = 1, p-value = 0.9604
#&gt; alternative hypothesis: true p is less than 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.0000000 0.5707377
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5366667
```
]
]

---

# Test for a single proportion: Example 2
.panelset[
.panel[.panel-name[Problem]
.smallest[A researcher who is studying the effects of income levels on breastfeeding of infants hypothesizes that countries where the income level is lower have a higher rate of infant breastfeeding than higher income countries. It is .hi.purple[known] that in Germany (high-income country), 22% of all babies are breastfeed. In Tajikistan (low-income country) researchers found that in a random sample of 500 new mothers that 125 were breastfeeding their infants. What can we conclude?]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.22\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&gt;} 0.22\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 5.874\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that countries where the income level is lower have a higher rate of infant breastfeeding than higher income countries.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 125, n = 500, p = 0.22, alternative = "greater")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  125 out of 500, null probability 0.22
#&gt; X-squared = 2.4505, df = 1, p-value = 0.05874
#&gt; alternative hypothesis: true p is greater than 0.22
#&gt; 95 percent confidence interval:
#&gt;  0.218598 1.000000
#&gt; sample estimates:
#&gt;    p 
#&gt; 0.25
```
]
]

---

# The one-sample Student's t test

So far we discuss about significance test for a single proportion. How can we perform a .purple[test for the mean of a population]? We will use .hi-pink[the Student's t test] (or simply t test) &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;, in which the test statistic follows a .pink[Student's t distribution] under the null hypothesis. 

The Student's t distributions were discovered in 1908 by William S. Gosset, who is a statistician employed by the Guinness brewing company. Gosset devised the t test as an economical way to monitor the quality of stout. At that time, the company forbade its scientists from publishing their findings, so Gosset published his statistical work under the pen name "Student" in the journal Biometrika, one of the mainstream journals in Statistics. So the Student's t test is named after Gosset's contributions. üçªü§ì

.footnote[.smallest[üëã The Student's t test is used when the population variance is unknown. In some uncommon cases where the population variance is known, we use the Z test, where the test statistic follows a standard normal distribution. Check out more [here](https://en.wikipedia.org/wiki/Z-test).]]

---

# The one-sample Student's t test

&lt;img src="pics/t_dist.png" width="50%" style="display: block; margin: auto;" /&gt;

- .smallest[A particular t distribution is specified by giving the .pink[degrees of freedom]. In the t test, the degree of freedom considered is] `\(\small n-1\)`.  
- .smallest[The probability density functions of the t distributions are similar in shape to the standard normal distribution. They are all symmetric about 0 and are bell-shaped. However, the t distributions have more probability in the tails than the standard normal distribution.]

---

# The one-sample t test: Example 1

.panelset[
.panel[.panel-name[Problem]
.smallest[The Nielsen Company, a global information and media company, announced that the U.S. cell phone subscribers spend 5.4 hours on average per month in watching videos on their phones. We want to know whether the U.S. college students .pink[spend different time watching videos on their phones than the average] with the following sample (in hours) of size 8: `$$11.9 \;\; 2.8 \;\; 3.0 \;\; 6.2 \;\; 4.7 \;\; 9.8 \;\; 11.1 \;\; 7.8.$$`]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \mu = 5.4\)` .smallest[and] `\(\small H_a: \mu \color{#e64173}{\neq} 5.4\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 20.4\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that the U.S. college students spend different time watching videos on their phones than the average.]
]
.panel[.panel-name[`R` Code ]

```r
data = c(11.9, 2.8, 3.0, 6.2, 4.7, 9.8, 11.1, 7.8)
t.test(x = data, mu = 5.4, alternative = "two.sided")
```

```
#&gt; 
#&gt; 	One Sample t-test
#&gt; 
#&gt; data:  data
#&gt; t = 1.4008, df = 7, p-value = 0.204
#&gt; alternative hypothesis: true mean is not equal to 5.4
#&gt; 95 percent confidence interval:
#&gt;   4.187213 10.137787
#&gt; sample estimates:
#&gt; mean of x 
#&gt;    7.1625
```
]
]

---

# The one-sample t test: Example 2
.panelset[
.panel[.panel-name[Problem]
An investor sues his broker and brokerage firm because he thinks his stock portfolio .pink[performs worse than the S&amp;P 500 average, 0.95%]. We collect the rates of return for 10 months when the account was managed by the broker: 
`\begin{align}
&amp;-2.36 \;\; -1.82 \;\; -0.16 \;\; -0.65 \;\; -2.14 \\ 
&amp;-1.63 \;\; -23.5 \;\; -1.25 \;\; -4.34 \;\; -1.01
\end{align}`

Please perform the t test following the steps and what conclusion can you draw? ü§î
]
.panel[.panel-name[Solution]
1. .purple[Define hypotheses:] `\(H_0: \mu = 0.0095\)` and `\(H_a: \mu \color{#e64173}{&lt;} 0.0095\)`.
2. .purple[Define] `\(\color{#6A5ACD}{\alpha}\)`: We consider `\(\alpha = 5\%\)`.
3. .purple[Compute p-value]: p-value = `\(5.583\%\)` (see computation tab for details).
4. .purple[Conclusion:] We have p-value &gt; `\(\alpha\)` and we cannot reject the null hypothesis. We don't have enough evidence to conclude that the investor's stock portfolio performs worse than the S&amp;P 500 average. üôÄ
]
.panel[.panel-name[`R` Code ]

```r
data = c(-2.36, -1.82, -0.16, -0.65, -2.14, -1.63, -23.5, -1.25, -4.34, -1.01)
t.test(x = data, mu = 0.0095, alternative = "less")
```

```
#&gt; 
#&gt; 	One Sample t-test
#&gt; 
#&gt; data:  data
#&gt; t = -1.7634, df = 9, p-value = 0.05583
#&gt; alternative hypothesis: true mean is less than 0.0095
#&gt; 95 percent confidence interval:
#&gt;       -Inf 0.1635933
#&gt; sample estimates:
#&gt; mean of x 
#&gt;    -3.886
```
]
]

---

# Limitations of the one-sample t test

.smallest[For the t test to work, the data is necessary to satisfy the followings:]
- .smallest[There are .pink[no outliers];]
- .smallest[The sample distribution is at least .pink[approximately normal] with no strong skewness.] 

.smallest[Therefore, before proceeding to any inference, we should check the data preliminarily using .purple[boxplot] or .purple[histogram] or .purple[QQ plot]] &lt;sup&gt;.smallest[üëã]&lt;/sup&gt; .smallest[to see if a t test can be used.]

.pull-left[

&lt;img src="lecture2_files/figure-html/unnamed-chunk-8-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="lecture2_files/figure-html/unnamed-chunk-9-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.footnote[.smallest[üëã Check out [QQ plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot).]]

---

# One-sample Wilcoxon signed rank test

- .smallest[What can we do if there are outliers in the data and/or if the population distribution is clearly not normal, especially when the sample size is very small? We use .hi-pink[the Wilcoxon signed rank test]!]

- .smallest[The .hi-purple[rank] is the position index of each observation when we order them from smallest to largest, starting with rank 1 for the smallest observation. ] 

- .smallest[The Wilcoxon signed rank test only uses the ranks (i.e. the ordering) of the observations, and makes no use of their actual numerical values. Therefore, it is a .hi-turquoise[nonparametric test].]

- .smallest[The Wilcoxon signed rank test depends on the .hi-purple[Wilcoxon signed rank statistic], which is the sum of the ranks of .purple[only the positive] values (or .purple[only the negative] values).]

- .smallest[Unlike the one-sample t test whose hypotheses are on the population mean, the Wilcoxon signed rank test states the hypotheses in terms of .hi-pink[population median].]

---

# Revisit the portfolio example

.panelset[
.panel[.panel-name[Problem]
.smallest[We recall the portfolio example in which we want to test if the investor's stock portfolio .pink[performs worse than the S&amp;P 500 average, 0.95%]. We recall the sample as follows:]
`\begin{align}
&amp;\small -2.36 \;\; -1.82 \;\; -0.16 \;\; -0.65 \;\; -2.14 \\ 
&amp;\small -1.63 \;\; -23.5 \;\; -1.25 \;\; -4.34 \;\; -1.01
\end{align}`

.smallest[Let's perform the Wilcoxon signed rank test and see if we draw different conclusion than the one-sample t test?]

1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \text{median} = 0.0095\)` .smallest[and] `\(\small H_a: \text{median} \color{#e64173}{&lt;} 0.0095\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value =] `\(\small 0.09766\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the investor's stock portfolio performs worse than the S&amp;P 500 average. ü•≥]

]
.panel[.panel-name[`R` Code ]

```r
data = c(-2.36, -1.82, -0.16, -0.65, -2.14, -1.63, -23.5, -1.25, -4.34, -1.01)
wilcox.test(x = data, mu = 0.0095, alternative = "less")
```

```
#&gt; 
#&gt; 	Wilcoxon signed rank test
#&gt; 
#&gt; data:  data
#&gt; V = 0, p-value = 0.0009766
#&gt; alternative hypothesis: true location is less than 0.0095
```
]
]

---

# Summary

- If the population distribution is actually normal, we will lose a bit of power using the one-sample Wilcoxon signed rank test compared to the one-sample t test. However, the difference is very small, so .pink[in practice we always recommend to use the one-sample Wilcoxon signed rank test].

- Stef: still need to add something like "we need to check symmetry of the distribution if use wilcoxon, otherwise we need to modify data beforehand". (I don't understand why the population distribution has to be symmetric? If so, median = mean then what's difference with t test?)

---

# Two-sample problems

.smallest[In practice, we often encounter problems that compare two samples, such as,] 
1. .smallest[A scientist is interested in comparing the effects of the Pfizer-BioNTech vaccine and the Moderna vaccine against Covid 19. üß¨ü¶†]
2. .smallest[A bank wants to know which of two proposed plans will most increase the use of its credit cards. üí∏üí≥]
3. .smallest[A psychologist wants to compare male and female college students' impression on a selected webpage. üì±üíª]

- .smallest[The goal of inference is to .purple[compare the means of the response variable in two groups.]]
- .smallest[Two .hi-turquoise[independent] random samples are separately selected from two .hi-turquoise[distinct] populations, and therefore, they can, for example, be of different sample sizes.]
- .smallest[We use .hi-pink[the two-sample t test] when the population variances are unknown &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;.]

.footnote[.smallest[üëã Similar to the one-sample t test, we use the two-sample Z test when both population variances are known, which is very uncommon in practice.]]

---

# The two-sample t test: Example

.panelset[
.panel[.panel-name[Problem]
.smallest[There is emerging evidence of a relationship between timing of feeding and weight regulation. More precisely, it is claimed that .pink[people who have their main meal early tend to lose more weight compared to people who eat late]. We collect weight loss (kg) data from 12 individuals, where 7 of them are early eaters and 5 of them are late eaters. .turquoise[We assume that the weight loss from these two groups both follow normal distributions.] We want to test if such claim is valid based on the observed sample: 
$$\small \text{Early eaters:} \;\; 6.3 \;\; 15.1 \;\; 9.4 \;\; 16.8 \;\; 10.2 \;\; 8.2 \;\; 12.7 \quad \text{Late eaters:} \;\; 7.8 \;\; 0.2 \;\; 1.5 \;\; 11.5 \;\; 4.6 $$
]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \mu_{\text{early}} = \mu_{\text{late}}\)` .smallest[and] `\(\small H_a: \mu_{\text{early}} \color{#e64173}{&gt;} \mu_{\text{late}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 2.122\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the early eaters tend to lose more weight compared to late eaters.]
]
.panel[.panel-name[`R` Code ]

```r
early_eaters = c(6.3, 15.1, 9.4, 16.8, 10.2, 8.2, 12.7)
late_eaters = c(7.8, 0.2, 1.5, 11.5, 4.6)
t.test(x = early_eaters, y = late_eaters, alternative = "greater")
```

```
#&gt; 
#&gt; 	Welch Two Sample t-test
#&gt; 
#&gt; data:  early_eaters and late_eaters
#&gt; t = 2.4351, df = 7.5918, p-value = 0.02122
#&gt; alternative hypothesis: true difference in means is greater than 0
#&gt; 95 percent confidence interval:
#&gt;  1.414346      Inf
#&gt; sample estimates:
#&gt; mean of x mean of y 
#&gt;  11.24286   5.12000
```
]
]

---

# Wilcoxon rank sum test

- .smallest[Similar to the Wilcoxon signed rank test as a robust &lt;sup&gt;.smallest[üëã]&lt;/sup&gt; alternative to the one-sample t test, we can use the .hi-pink[Wilcoxon rank sum test] (also called the Mann-Whitney test) when the normality condition is not satisfied to use two-sample t test.]
- .smallest[The Wilcoxon rank sum test depends on the .hi-purple[Wilcoxon rank sum statistic], which is the .purple[sum of the ranks of one sample]. As it only uses the ranks of the observations, it is a .hi-turquoise[nonparametric test].]
- .smallest[In the simplest form, the Wilcoxon rank sum test states the hypotheses in terms of .hi-pink[population median]. However, more precisely, it actually tests whether the two distributions are the same, i.e. üòµ]
`\begin{align}
&amp; \small H_0: \text{The two distributions are the same.} \\
&amp; \small H_a: \text{One distribution has values that are systematically larger (or smaller). }
\end{align}`

.footnote[.smallest[üëã Informally, a robust method is such that it is not overly affected by outliers. The usual one-sample and two-sample t tests are somehow robust in the sense that their results of inference are not very sensitive to moderate lack of normality when the samples are sufficiently large. However, they may still fail when the population distribution shows strong skewness, especially when we have only a few observations.]]

---

# Revisit the weight loss example

.panelset[
.panel[.panel-name[Problem]
.smallest[Let's recall the previous weight loss example. We want to test if .pink[early eaters tend to lose more weight than late eaters]. This time, .turquoise[we assume nothing on the distributions of the weight loss from these two groups]. Recall the sample as follows: 
$$\small \text{Early eaters:} \;\; 6.3 \;\; 15.1 \;\; 9.4 \;\; 16.8 \;\; 10.2 \;\; 8.2 \;\; 12.7 \quad \text{Late eaters:} \;\; 7.8 \;\; 0.2 \;\; 1.5 \;\; 11.5 \;\; 4.6 $$
]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \text{median}_{\text{early}} = \text{median}_{\text{late}}\)` .smallest[and] `\(\small H_a: \text{median}_{\text{early}} \color{#e64173}{&gt;} \text{median}_{\text{late}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 2.399\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the early eaters tend to lose more weight compared to late eaters.]
]
.panel[.panel-name[`R` Code ]

```r
early_eaters = c(6.3, 15.1, 9.4, 16.8, 10.2, 8.2, 12.7)
late_eaters = c(7.8, 0.2, 1.5, 11.5, 4.6)
wilcox.test(x = early_eaters, y = late_eaters, alternative = "greater")
```

```
#&gt; 
#&gt; 	Wilcoxon rank sum test
#&gt; 
#&gt; data:  early_eaters and late_eaters
#&gt; W = 30, p-value = 0.02399
#&gt; alternative hypothesis: true location shift is greater than 0
```
]
]

---

# Exercise

An airline company is planning to purchase some new wide-body airliners and narrows down its candidates to Boeing 747 and Lockheed L-1011 TriStar. The company wants to know .pink[if Boeing 747 has longer lifespans than Lockheed L-1011 TriStar] based on the following available samples (in years): 
`\begin{align}
&amp; \text{Boeing} \;\; 29.2 \;\; 27.9 \;\; 28.4 \;\; 22.5 \;\; 26.1 \;\; 19.8 \;\; 27.7 \;\; 27.2 \;\; 31.2 \;\; 28.7 \\
&amp; \text{Lockheed} \;\; 22.4 \;\; 20.2 \;\; 22.9 \;\; 25.1 \;\; 21.8 \;\; 24.2 \;\; 17.1 \;\; 30.5 \;\; 25.8 \;\; 22.6 \\
\end{align}`

Perform a test you judge appropriate. What conclusion can you draw? üßê

---

# Solution: the two-sample t test

.panelset[
.panel[.panel-name[Normality]

.pull-left[
&lt;img src="lecture2_files/figure-html/unnamed-chunk-13-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="lecture2_files/figure-html/unnamed-chunk-14-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]
]
.panel[.panel-name[Solution]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \mu_{\text{B}} = \mu_{\text{L}}\)` .smallest[and] `\(\small H_a: \mu_{\text{B}} \color{#e64173}{&gt;} \mu_{\text{L}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \color{#e64173}{\alpha = 2\%}\)` .smallest[(see computation tab for details).]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 1.571\%\)`.smallest[.]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that Boeing 747 has longer lifespans than Lockheed L-1011 TriStar.] 
]
.panel[.panel-name[`R` Code ]

```r
boeing = c(29.2, 27.9, 28.4, 22.5, 26.1, 19.8, 27.7, 27.2, 31.2, 28.7)
lockheed = c(22.4, 20.2, 22.9, 25.1, 21.8, 24.2, 17.1, 30.5, 25.8, 22.6)
t.test(x = boeing, y = lockheed, alternative = "greater")
```

```
#&gt; 
#&gt; 	Welch Two Sample t-test
#&gt; 
#&gt; data:  boeing and lockheed
#&gt; t = 2.3341, df = 17.94, p-value = 0.01571
#&gt; alternative hypothesis: true difference in means is greater than 0
#&gt; 95 percent confidence interval:
#&gt;  0.9275616       Inf
#&gt; sample estimates:
#&gt; mean of x mean of y 
#&gt;     26.87     23.26
```
]
]

---

# Solution: Wilcoxon rank sum test

.panelset[
.panel[.panel-name[Solution]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \text{median}_{\text{B}} = \text{median}_{\text{L}}\)` .smallest[and] `\(\small H_a: \text{median}_{\text{B}} \color{#e64173}{&gt;} \text{median}_{\text{L}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \color{#e64173}{\alpha = 2\%}\)` .smallest[(see computation tab for details).]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 1.773\%\)`.smallest[.]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that Boeing 747 has longer lifespans than Lockheed L-1011 TriStar.]
]
.panel[.panel-name[`R` Code ]

```r
boeing = c(29.2, 27.9, 28.4, 22.5, 26.1, 19.8, 27.7, 27.2, 31.2, 28.7)
lockheed = c(22.4, 20.2, 22.9, 25.1, 21.8, 24.2, 17.1, 30.5, 25.8, 22.6)
wilcox.test(x = boeing, y = lockheed, alternative = "greater")
```

```
#&gt; 
#&gt; 	Wilcoxon rank sum test
#&gt; 
#&gt; data:  boeing and lockheed
#&gt; W = 78, p-value = 0.01773
#&gt; alternative hypothesis: true location shift is greater than 0
```
]
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
