<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="St√©phane Guerrier &amp; Yuming Zhang" />
    <meta name="date" content="2021-01-08" />
    <link href="lecture2_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="lecture2_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="lecture2_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link href="lecture2_files/tile-view-0.2.4/tile-view.css" rel="stylesheet" />
    <script src="lecture2_files/tile-view-0.2.4/tile-view.js"></script>
    <link href="lecture2_files/panelset-0.2.4/panelset.css" rel="stylesheet" />
    <script src="lecture2_files/panelset-0.2.4/panelset.js"></script>
    <script src="lecture2_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="lecture2_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="lecture2_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to Statistics
## Part II: Introduction to Statistical Inference
### St√©phane Guerrier &amp; Yuming Zhang
### 8 January 2021

---










# Review

- .smallest[.hi-pink[Statistical inference] allows to infer the properties of a population based on an observed sample.]
- .smallest[For example, .hi-pink[proportion estimation]] `\(\color{#e64173}{\hat{p}}\)` .smallest[is .hi-purple[random] as it is sample dependent. Therefore, we need to access the .hi-purple[uncertainty] of] `\(\hat{p}\)`.
- .smallest[One common approach to measure uncertainty is to use .hi-pink[confidence intervals], which rely on .hi-pink[Central Limit Theorem]. In the case of proportion estimation, we have] `$$\small \hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(\color{#e64173}{p}, \color{#6A5ACD}{\frac{p(1-p)}{n}}\Bigg).$$`
- .smallest[Confidence intervals correspond to a range of values that are likely to include the population value with .hi-purple[a certain level of confidence]. The] `\(1-\alpha\)` .smallest[confidence interval for] `\(p\)` .smallest[is given by] `\(\color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}\)` .smallest[, and obviously, it is random.]
- .smallest[In Statistics, a decision or prediction can never be made with certainty. There always exists .hi-purple[a trade-off between the risk and the precision of the conclusion], and how much risk is acceptable depends on the context.]

---

# How to test a (scientific) hypothesis?

Stef: could you do the following as you suggest? I'm not sure what exactly you want to add here... (as all the concepts about hypothesis come later, I don't know if here is the correct place to add a summary of testing process)...

Between slides 2 and 3 I would add a slide that summarises: [testing process](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing).

Maybe add that this is the process that the scientific generally accepts‚Ä¶

Maybe somewhere we could add: If there's one takeaway from the ASA statement, it's that p-values are not badges of truth and p &lt; 0.05 is not a line that separates real results from false ones. They're simply one piece of a puzzle that should be considered in the context of other evidence. (It's from [here](https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/))

---

# How to test a (scientific) hypothesis?

Stef: adapt with previous slide, change title

- .smallest[An alternative summary measure of uncertainty is provided  by .hi-pink[p-values] that take values between 0% and 100%.]
- .smallest[However, .hi-purple[p-values have been misused] many times because understanding what they mean is not intuitive.]

&lt;div align="center"&gt;
&lt;iframe src="https://fivethirtyeight.abcnews.go.com/video/embed/56150342" width="512" height="288" scrolling="no" style="border:none;" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt; 

üëã .tiny[If you want to know more have a look [here](https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/).]

---

# A hypothesis testing

Stef: want to add a John Oliver video here...

- A p-value is associated to (a couple of) .purple[hypotheses] about the phenomenon under investigation, such as
1. Coffee consumption increases blood pressure (really üôÑ ‚òï?)
2. Republican politicians are bad/good for the American Economy.
3. A glass of red wine is as good as an hour at the gym (üç∑ üèÉ üòÜ).

Yuming: maybe we can remove the following point (as it's discussed in the next slide)

- More precisely, a hypothesis testing is designed to assess the strength of evidence against a baseline hypothesis called .pink[null hypothesis] `\(\color{#e64173}{H_0}\)` and in favor of another hypothesis called .pink[alternative hypothesis] `\(\color{#e64173}{H_a}\)`.

---

# A hypothesis testing

- In the Biden-Trump example, recall that we want to verify if Biden will win the popular vote. Then we can translate this into the following hypotheses:
.center[
`\(H_0: p = 0.5\)` and `\(H_a: p &gt; 0.5\)`.
]
- In a hypothesis test, the statement being tested is called the .hi-pink[null hypothesis] `\(\color{#e64173}{H_0}\)`. A hypothesis test is designed to assess the strength of the evidence against the null hypothesis.
- The .hi-pink[alternative hypothesis] `\(\color{#e64173}{H_a}\)` is the statement we hope or suspect to be true instead of `\(H_0\)`.
- Each hypothesis .purple[excludes the other], so that one can .purple[exclude one in favor of the other] using the data.

---

# A hypothesis testing

|                 | `\(H_0\)` is true                               | `\(H_0\)` is false                          |
| --------------- |---------------------------------------------| ----------------------------------------|
| Accept `\(H_0\)`    | `\(\text{Correct inference (prob=}1-\alpha)\)`  | `\(\text{Type II error (prob=}1-\beta)\)`   |
| Reject `\(H_0\)`    | `\(\text{Type I error (prob=}\alpha)\)`         | `\(\text{Correct inference (prob=}\beta)\)` |

- If we reject `\(H_0\)` when in fact `\(H_0\)` is true, this is a .hi-pink[type I error] (also called .hi-pink[false positive]). If we accept `\(H_0\)` when in fact `\(H_a\)` is true, this is a .hi-purple[type II error] (also called .hi-purple[false negative]).
- A test is of .hi-pink[significance level] `\(\color{#e64173}{\alpha}\)` when the probability to make a type I error is `\(\alpha\)`. Usually we consider `\(\alpha = 5\%\)`, however, this can vary depending on the context.
- A test if of .hi-purple[power] `\(\color{#6A5ACD}{\beta}\)` when the probability to make a type II error is `\(1-\beta\)`. In other words, the power of a test is its probability to reject `\(H_0\)` when `\(H_0\)` is false.

---

# Test statistic and P-value

- .smallest[A hypothesis testing is based on a .hi-pink[test statistic], which measures the difference between the sample estimate and the hypothesized value in terms of its standard deviation, i.e.] 
`$$\small \text{test statistic} = \frac{\text{sample estimate - hypothesized value}}{\text{standard deviation of sample estimate}}.$$`

- .smallest[For example, consider a test for a single proportion with] `\(\small H_0: p = p_0\)` .smallest[and] `\(\small H_a: p &gt; p_0\)`.smallest[, the corresponding test statistic can be computed as] `$$Z = \frac{\hat{p}-\color{#e64173}{p_0}}{\color{#6A5ACD}{\sqrt{\frac{p_0(1-p_0)}{n}}}} \overset{\cdot}{\sim} \mathcal{N}(0,1).$$`
- .smallest[The .hi-purple[p-value] is defined as the probability, assuming that] `\(\small H_0\)` .smallest[is true, that the test statistic will take a value at least as extreme as that actually observed.] ü§Øüò±
- .smallest[Informally, .pink[a p-value can be understood as a measure of plausibility of the null hypothesis given the data]. Small p-value indicates strong evidence against] `\(\small H_0\)`.

---

# Test statistic and P-value

&lt;img src="pics/p_value.png" width="45%" style="display: block; margin: auto;" /&gt;

üëã .smallest[If you want to know more have a look [here](https://xkcd.com/1478/).]

---

# Test statistic and P-value

- When the p-value is small enough (i.e. smaller than the significance level `\(\alpha\)`), one says that the test based on the null and alternative hypotheses is .hi-pink[significant] or that the null hypothesis is rejected in favor of the alternative. .purple[This is generally what we want because it "verifies" our (research) hypothesis].
- When the p-value is not small enough, with the available data, we cannot reject the null hypothesis so .hi-pink[nothing] can be concluded. ü§î
- With a sample of data, the obtained p-value summarizes somehow the .hi-pink[incompatibility between the data and the model] (random process) constructed under the set of assumptions.

.center[
.purple["Absence of evidence is not evidence of absence." &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;]
]

.footnote[.smallest[üëã] From the British Medical Journal.]

---

# Test for a single proportion: Example 1

.panelset[
.panel[.panel-name[Problem]
.smallest[Returning to our Biden-Trump example, suppose we believe (or hope to show that) .pink[Biden will have more than 50% of the votes at a significance level of 5%]. We collect data with] `\(\small n = 600\)` .smallest[and] `\(\small m = 322\)`.smallest[. We will consider the following steps to set up the test:]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.5\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&gt;} 0.5\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 3.959\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the proportion of voters for Biden is greater than 50%.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 322, n = 600, p = 0.5, alternative = "greater")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  322 out of 600, null probability 0.5
#&gt; X-squared = 3.0817, df = 1, p-value = 0.03959
#&gt; alternative hypothesis: true p is greater than 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.5022582 1.0000000
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5366667
```
]
]

---

# Test for a single proportion: Example 1

.panelset[
.panel[.panel-name[Problem]
.smallest[What if we want to check if .pink[Trump will have more than 50% of the votes at the 95% confidence level]? Using the same data, we set up the test as follows:]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.5\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&lt;} 0.5\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)` .smallest[  (which corresponds to the 95% confidence level).]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 96.04\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that Trump will have more than 50% of the votes.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 322, n = 600, p = 0.5, alternative = "less")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  322 out of 600, null probability 0.5
#&gt; X-squared = 3.0817, df = 1, p-value = 0.9604
#&gt; alternative hypothesis: true p is less than 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.0000000 0.5707377
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5366667
```
]
]

---

# Test for a single proportion: Example 2
.panelset[
.panel[.panel-name[Problem]
.smallest[A researcher who is studying the effects of income levels on breastfeeding of infants hypothesizes that .pink[countries where the income level is lower have a higher rate of infant breastfeeding than higher income countries]. It is .hi.purple[known] that in Germany (high-income country), 22% of all babies are breastfeed. In Tajikistan (low-income country) researchers found that in a random sample of 500 new mothers that 125 were breastfeeding their infants. What can we conclude?]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.22\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&gt;} 0.22\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 5.874\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that countries where the income level is lower have a higher rate of infant breastfeeding than higher income countries.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 125, n = 500, p = 0.22, alternative = "greater")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  125 out of 500, null probability 0.22
#&gt; X-squared = 2.4505, df = 1, p-value = 0.05874
#&gt; alternative hypothesis: true p is greater than 0.22
#&gt; 95 percent confidence interval:
#&gt;  0.218598 1.000000
#&gt; sample estimates:
#&gt;    p 
#&gt; 0.25
```
]
]

---

# The one-sample Student's t-test

.smallest[So far we discuss about significance test for a single proportion. How can we perform a .purple[test for the mean of a population]? We will use .hi-pink[the Student's t-test] (or simply t-test) &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;, in which the test statistic follows a .pink[Student's t distribution] under the null hypothesis. ]

.smallest[The Student's t distributions were discovered in 1908 by William S. Gosset, who is a statistician employed by the Guinness brewing company. Gosset devised the t-test as an economical way to monitor the quality of stout. At that time, the company forbade its scientists from publishing their findings, so Gosset published his statistical work under the pen name "Student" in the journal Biometrika (which is nowadays still one of the leading journals in Statistics). So the Student's t-test is named after Gosset's contributions. üçªü§ì]
&lt;img src="pics/gosset_biometrika.png" width="55%" style="display: block; margin: auto;" /&gt;

.footnote[.smallest[üëã The Student's t-test is used when the population variance is unknown. In some uncommon cases where the population variance is known, we use the Z-test, where the test statistic follows a standard normal distribution. Check out more [here](https://en.wikipedia.org/wiki/Z-test).]]

---

# The one-sample Student's t-test

&lt;img src="pics/t_dist.png" width="50%" style="display: block; margin: auto;" /&gt;

- .smallest[A particular t distribution is specified by giving the .pink[degrees of freedom]. In the t-test, the degrees of freedom considered is] `\(\small n-1\)`.  
- .smallest[The probability density functions of the t distributions are similar in shape to the standard normal distribution. They are all symmetric about 0 and are bell-shaped. However, the t distributions have more probability in the tails than the standard normal distribution.]

---

# The one-sample t-test: Example 1

.panelset[
.panel[.panel-name[Problem]
.smallest[The Nielsen Company, a global information and media company, announced that the U.S. cell phone subscribers spend 5.4 hours on average per month in watching videos on their phones. We want to know whether the U.S. college students .pink[spend different time watching videos on their phones than the average] with the following sample (in hours) of size 8: `$$11.9 \;\; 2.8 \;\; 3.0 \;\; 6.2 \;\; 4.7 \;\; 9.8 \;\; 11.1 \;\; 7.8.$$`]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \mu = 5.4\)` .smallest[and] `\(\small H_a: \mu \color{#e64173}{\neq} 5.4\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 20.4\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that the U.S. college students spend different time watching videos on their phones than the average.]
]
.panel[.panel-name[`R` Code ]

```r
data = c(11.9, 2.8, 3.0, 6.2, 4.7, 9.8, 11.1, 7.8)
t.test(x = data, mu = 5.4, alternative = "two.sided")
```

```
#&gt; 
#&gt; 	One Sample t-test
#&gt; 
#&gt; data:  data
#&gt; t = 1.4008, df = 7, p-value = 0.204
#&gt; alternative hypothesis: true mean is not equal to 5.4
#&gt; 95 percent confidence interval:
#&gt;   4.187213 10.137787
#&gt; sample estimates:
#&gt; mean of x 
#&gt;    7.1625
```
]
]

---

# The one-sample t-test: Example 2
.panelset[
.panel[.panel-name[Problem]
An investor sues his broker and brokerage firm because he thinks his stock portfolio .pink[performs worse than the S&amp;P 500 average, 0.95%]. We collect the rates of return (in %) for 10 months when the account was managed by the broker: 
`$$\small -2.36 \;\; -1.82 \;\; 0.46 \;\; 0.65 \;\; -2.14 \;\; -1.63 \;\; -25.5 \;\; 0.25 \;\; -4.34 \;\; 0.91$$`

Please perform the t-test following the steps and what conclusion can you draw? ü§î
]
.panel[.panel-name[Solution]
1. .purple[Define hypotheses:] `\(H_0: \mu = 0.95\)` and `\(H_a: \mu \color{#e64173}{&lt;} 0.95\)`.
2. .purple[Define] `\(\color{#6A5ACD}{\alpha}\)`: We consider `\(\alpha = 5\%\)`.
3. .purple[Compute p-value]: p-value = `\(5.237\%\)` (see R code tab for details).
4. .purple[Conclusion:] We have p-value &gt; `\(\alpha\)` and we cannot reject the null hypothesis. We don't have enough evidence to conclude that the investor's stock portfolio performs worse than the S&amp;P 500 average. üôÄ
]
.panel[.panel-name[`R` Code ]

```r
data = c(-2.36, -1.82, 0.46, 0.65, -2.14, -1.63, -25.5, 0.25, -4.34, 0.91)
t.test(x = data, mu = 0.95, alternative = "less")
```

```
#&gt; 
#&gt; 	One Sample t-test
#&gt; 
#&gt; data:  data
#&gt; t = -1.8039, df = 9, p-value = 0.05237
#&gt; alternative hypothesis: true mean is less than 0.95
#&gt; 95 percent confidence interval:
#&gt;     -Inf 1.02288
#&gt; sample estimates:
#&gt; mean of x 
#&gt;    -3.552
```
]
]

---

# Limitations of the one-sample t-test

.smallest[For the t-test to work, the data is necessary to satisfy the followings:]
- .smallest[There are .pink[no outliers];]
- .smallest[The sample distribution is at least .pink[approximately normal] with no strong skewness.] 

.smallest[Therefore, before proceeding to any inference, we should check the data preliminarily using .purple[boxplot] or .purple[histogram] or .purple[QQ plot]] &lt;sup&gt;.smallest[üëã]&lt;/sup&gt; .smallest[to see if a t-test can be used.]

.pull-left[

&lt;img src="lecture2_files/figure-html/unnamed-chunk-10-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="lecture2_files/figure-html/unnamed-chunk-11-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.footnote[.smallest[üëã Check out [QQ plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot).]]

---

# One-sample Wilcoxon signed rank test

- .smallest[What can we do if there are outliers in the data and/or if the population distribution is clearly not normal, especially when the sample size is very small? We use the .hi-pink[Wilcoxon signed rank test]!]

- .smallest[The .hi-purple[rank] is the position index of each observation when we order them from smallest to largest, starting with rank 1 for the smallest observation. ] 

- .smallest[The Wilcoxon signed rank test only uses the ranks (i.e. the ordering) of the observations, and makes no use of their actual numerical values. Therefore, it is a .hi-turquoise[nonparametric test].]

- .smallest[The Wilcoxon signed rank test depends on the .hi-purple[Wilcoxon signed rank statistic], which is the sum of the ranks of .purple[only the positive] values (or .purple[only the negative] values).]

- .smallest[Unlike the one-sample t-test whose hypotheses are on the population mean, the Wilcoxon signed rank test states the hypotheses in terms of .hi-pink[population median].]

---

# Revisit the portfolio example

.panelset[
.panel[.panel-name[Problem]
.smallest[We recall the portfolio example in which we want to test if the investor's stock portfolio .pink[performs worse than the S&amp;P 500 average, 0.95%]. We recall the sample as follows:]
`$$\small -2.36 \;\; -1.82 \;\; 0.46 \;\; 0.65 \;\; -2.14 \;\; -1.63 \;\; -25.5 \;\; 0.25 \;\; -4.34 \;\; 0.91$$`

.smallest[Let's perform the Wilcoxon signed rank test and see if we draw different conclusion than the one-sample t-test?]

1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \text{median} = 0.95\)` .smallest[and] `\(\small H_a: \text{median} \color{#e64173}{&lt;} 0.95\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value =] `\(\small 0.09766\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the investor's stock portfolio performs worse than the S&amp;P 500 average. ü•≥]

]
.panel[.panel-name[`R` Code ]

```r
data = c(-2.36, -1.82, 0.46, 0.65, -2.14, -1.63, -25.5, 0.25, -4.34, 0.91)
wilcox.test(x = data, mu = 0.95, alternative = "less")
```

```
#&gt; 
#&gt; 	Wilcoxon signed rank test
#&gt; 
#&gt; data:  data
#&gt; V = 0, p-value = 0.0009766
#&gt; alternative hypothesis: true location is less than 0.95
```
]
]

---

# Summary

- If the population distribution is actually normal, we will lose a bit of power using the one-sample Wilcoxon signed rank test compared to the one-sample t-test. However, the difference is very small, so .pink[in practice we always recommend to use the one-sample Wilcoxon signed rank test.]

- Stef: still need to add something like "we need to check symmetry of the distribution if use wilcoxon, otherwise we need to modify data beforehand". (I don't understand why the population distribution has to be symmetric? If so, median = mean then what's difference with t-test?)

---

# Two-sample problems

.smallest[In practice, we often encounter problems that compare two samples. For example,] 
1. .smallest[A scientist is interested in comparing the effects of the Pfizer-BioNTech vaccine and the Moderna vaccine against Covid 19. üß¨ü¶†]
2. .smallest[A bank wants to know which of two proposed plans will most increase the use of its credit cards. üí∏üí≥]
3. .smallest[A psychologist wants to compare male and female college students' impression on a selected webpage. üì±üíª]

- .smallest[The goal of inference is to .purple[compare the means of the response variable in two groups.]]
- .smallest[Two .hi-turquoise[independent] random samples are separately selected from two .hi-turquoise[distinct] populations, and therefore, they can, for example, be of different sample sizes.]
- .smallest[We use .hi-pink[the two-sample t-test] when the population variances are unknown &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;.]

.footnote[.smallest[üëã Similar to the one-sample t-test, we use the two-sample Z-test when both population variances are known, which is very uncommon in practice.]]

---

# The two-sample t-test: Example

.panelset[
.panel[.panel-name[Problem]
.smallest[There is emerging evidence of a relationship between timing of feeding and weight regulation. More precisely, it is claimed that .pink[people who have their main meal early tend to lose more weight compared to people who eat late]. We collect weight loss (in kg) data from 12 individuals, where 7 of them are early eaters and 5 of them are late eaters. .turquoise[We assume that the weight loss from these two groups both follow normal distributions.] We want to test if such claim is valid based on the observed sample: 
$$\small \text{Early eaters:} \;\; 6.3 \;\; 15.1 \;\; 9.4 \;\; 16.8 \;\; 10.2 \;\; 8.2 \;\; 12.7 \quad \text{Late eaters:} \;\; 7.8 \;\; 0.2 \;\; 1.5 \;\; 11.5 \;\; 4.6 $$
]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \mu_{\text{early}} = \mu_{\text{late}}\)` .smallest[and] `\(\small H_a: \mu_{\text{early}} \color{#e64173}{&gt;} \mu_{\text{late}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 2.122\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the early eaters tend to lose more weight compared to late eaters.]
]
.panel[.panel-name[`R` Code ]

```r
early_eaters = c(6.3, 15.1, 9.4, 16.8, 10.2, 8.2, 12.7)
late_eaters = c(7.8, 0.2, 1.5, 11.5, 4.6)
t.test(x = early_eaters, y = late_eaters, alternative = "greater")
```

```
#&gt; 
#&gt; 	Welch Two Sample t-test
#&gt; 
#&gt; data:  early_eaters and late_eaters
#&gt; t = 2.4351, df = 7.5918, p-value = 0.02122
#&gt; alternative hypothesis: true difference in means is greater than 0
#&gt; 95 percent confidence interval:
#&gt;  1.414346      Inf
#&gt; sample estimates:
#&gt; mean of x mean of y 
#&gt;  11.24286   5.12000
```
]
]

---

# Wilcoxon rank sum test

- .smallest[Similar to the Wilcoxon signed rank test as a robust &lt;sup&gt;.smallest[üëã]&lt;/sup&gt; alternative to the one-sample t-test, we can use the .hi-pink[Wilcoxon rank sum test] (also called the Mann-Whitney test) when the normality condition is not satisfied to use two-sample t-test.]
- .smallest[The Wilcoxon rank sum test depends on the .hi-purple[Wilcoxon rank sum statistic], which is the .purple[sum of the ranks of one sample]. As it only uses the ranks of the observations, it is a .hi-turquoise[nonparametric test].]
- .smallest[In the simplest form, the Wilcoxon rank sum test states the hypotheses in terms of .hi-pink[population median]. However, more precisely, it actually tests whether the two distributions are the same, i.e. üòµ]
`\begin{align}
&amp; \small H_0: \text{The two distributions are the same.} \\
&amp; \small H_a: \text{One distribution has values that are systematically larger (or smaller). }
\end{align}`

.footnote[.smallest[üëã Informally, a robust method is such that it is not overly affected by outliers. The usual one-sample and two-sample t-tests are somehow robust in the sense that their results of inference are not very sensitive to moderate lack of normality when the samples are sufficiently large. However, they may still fail when the population distribution shows strong skewness, especially when we have only a few observations.]]

---

# Revisit the weight loss example

.panelset[
.panel[.panel-name[Problem]
.smallest[Let's recall the previous weight loss example. We want to test if .pink[early eaters tend to lose more weight than late eaters]. This time, .turquoise[we assume nothing on the distributions of the weight loss from these two groups]. Recall the samples as follows: 
$$\small \text{Early eaters:} \;\; 6.3 \;\; 15.1 \;\; 9.4 \;\; 16.8 \;\; 10.2 \;\; 8.2 \;\; 12.7 \quad \text{Late eaters:} \;\; 7.8 \;\; 0.2 \;\; 1.5 \;\; 11.5 \;\; 4.6 $$
]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \text{median}_{\text{early}} = \text{median}_{\text{late}}\)` .smallest[and] `\(\small H_a: \text{median}_{\text{early}} \color{#e64173}{&gt;} \text{median}_{\text{late}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 2.399\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the early eaters tend to lose more weight compared to late eaters.]
]
.panel[.panel-name[`R` Code ]

```r
early_eaters = c(6.3, 15.1, 9.4, 16.8, 10.2, 8.2, 12.7)
late_eaters = c(7.8, 0.2, 1.5, 11.5, 4.6)
wilcox.test(x = early_eaters, y = late_eaters, alternative = "greater")
```

```
#&gt; 
#&gt; 	Wilcoxon rank sum test
#&gt; 
#&gt; data:  early_eaters and late_eaters
#&gt; W = 30, p-value = 0.02399
#&gt; alternative hypothesis: true location shift is greater than 0
```
]
]

---

# Exercise

An airline company is planning to purchase some new wide-body airliners and narrows down its candidates to Boeing 747 and Lockheed L-1011 TriStar. The company wants to know .pink[if Boeing 747 has longer lifespans than Lockheed L-1011 TriStar] based on the following available samples (in years): 
`\begin{align}
&amp; \text{Boeing} \;\; 29.2 \;\; 27.9 \;\; 28.4 \;\; 22.5 \;\; 26.1 \;\; 19.8 \;\; 27.7 \;\; 27.2 \;\; 31.2 \;\; 28.7 \\
&amp; \text{Lockheed} \;\; 22.4 \;\; 20.2 \;\; 22.9 \;\; 25.1 \;\; 21.8 \;\; 24.2 \;\; 17.1 \;\; 30.5 \;\; 25.8 \;\; 22.6 \\
\end{align}`

Perform a test you judge appropriate. What conclusion can you draw? üßê

---

# Solution: the two-sample t-test

.panelset[
.panel[.panel-name[Normality]

.pull-left[
&lt;img src="lecture2_files/figure-html/unnamed-chunk-15-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="lecture2_files/figure-html/unnamed-chunk-16-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]
]
.panel[.panel-name[Solution]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \mu_{\text{B}} = \mu_{\text{L}}\)` .smallest[and] `\(\small H_a: \mu_{\text{B}} \color{#e64173}{&gt;} \mu_{\text{L}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \color{#e64173}{\alpha = 2\%}\)` .smallest[(see R code tab for details).]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 1.571\%\)`.smallest[.]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that Boeing 747 has longer lifespans than Lockheed L-1011 TriStar.] 
]
.panel[.panel-name[`R` Code ]

```r
boeing = c(29.2, 27.9, 28.4, 22.5, 26.1, 19.8, 27.7, 27.2, 31.2, 28.7)
lockheed = c(22.4, 20.2, 22.9, 25.1, 21.8, 24.2, 17.1, 30.5, 25.8, 22.6)
t.test(x = boeing, y = lockheed, alternative = "greater")
```

```
#&gt; 
#&gt; 	Welch Two Sample t-test
#&gt; 
#&gt; data:  boeing and lockheed
#&gt; t = 2.3341, df = 17.94, p-value = 0.01571
#&gt; alternative hypothesis: true difference in means is greater than 0
#&gt; 95 percent confidence interval:
#&gt;  0.9275616       Inf
#&gt; sample estimates:
#&gt; mean of x mean of y 
#&gt;     26.87     23.26
```
]
]

---

# Solution: Wilcoxon rank sum test

.panelset[
.panel[.panel-name[Solution]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: \text{median}_{\text{B}} = \text{median}_{\text{L}}\)` .smallest[and] `\(\small H_a: \text{median}_{\text{B}} \color{#e64173}{&gt;} \text{median}_{\text{L}}\)`.smallest[.]
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \color{#e64173}{\alpha = 2\%}\)` .smallest[(see R code tab for details).]
3. .smallest[.purple[Compute p-value:] p-value =] `\(\small 1.773\%\)`.smallest[.]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that Boeing 747 has longer lifespans than Lockheed L-1011 TriStar.]
]
.panel[.panel-name[`R` Code ]

```r
boeing = c(29.2, 27.9, 28.4, 22.5, 26.1, 19.8, 27.7, 27.2, 31.2, 28.7)
lockheed = c(22.4, 20.2, 22.9, 25.1, 21.8, 24.2, 17.1, 30.5, 25.8, 22.6)
wilcox.test(x = boeing, y = lockheed, alternative = "greater")
```

```
#&gt; 
#&gt; 	Wilcoxon rank sum test
#&gt; 
#&gt; data:  boeing and lockheed
#&gt; W = 78, p-value = 0.01773
#&gt; alternative hypothesis: true location shift is greater than 0
```
]
]

---

# How about more than 2 samples? üòú

In practice, we often even encounter situations where we need to .pink[compare the means of more than 2 groups]. For example,

1. A scientist wants to study the effects of the Pfizer-BioNTech, the Moderna, and the Chinese vaccine against Covid 19 compared to the placebo.
2. A nutritionist wants to compare the diet habits of female from different ages (10-20, 21-30, ...) 
3. A restaurant wants to compare the consumptions among 3 different kinds of pizzas. üçïüç¥ü§§

Can we simply do multiple tests with what we have learned? ü§î

---

# Jelly beans example

.purple[Are jelly beans causing acne? Maybe... but why only green ones?] ü§® 

&lt;img src="pics/green.png" width="45%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [xkcd](https://xkcd.com/882/)]
---

# Are jelly beans causing acne?

&lt;br&gt;
&lt;img src="pics/green1.png" width="85%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [xkcd](https://xkcd.com/882/)]

---

# Maybe a specific color?

&lt;br&gt;
&lt;img src="pics/green2.png" width="76%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [xkcd](https://xkcd.com/882/)]

---

# Maybe a specific color?

&lt;br&gt;
&lt;img src="pics/green3.png" width="75%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [xkcd](https://xkcd.com/882/)]

---

# And finally...

&lt;img src="pics/green.png" width="45%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [xkcd](https://xkcd.com/882/)]

üëã .smallest[If you want to know more about this comics have a look [here](https://www.explainxkcd.com/wiki/index.php/882:_Significant).]

---

# ‚ò†Ô∏è Multiple testing can be dangerous!

- .smaller[Remember that a p-value is .hi-pink[random] as its value depends on the data.]
- .smaller[Hence, by chance, it might happen that while the null hypothesis cannot be rejected (supposing it is true), that the p-value is smaller than the set threshold. With the latter chosen as 5%, then, on average, the (sample) p-value is below 5% .purple[once in twenty times!]]
- .smaller[If multiple hypotheses are tested, the chance of observing a rare event increases, and therefore, the chance to incorrectly reject a null hypothesis (i.e., making a Type I error) increases.]
- .smaller[Hence .hi-pink[performing multiple tests, with the same or different data, is dangerous ‚ö†Ô∏è] (but very common! üòü) as it automatically leads to .pink[significant results, when actually there are none!]]

---

# Methods to remedy such problem

- .smallest[The .hi-pink[Bonferroni correction] is one of oldest methods proposed to counteract the problem of multiple testing (i.e. potential increased chance to make Type I errors). ]
- .smallest[.purple[It-tests each individual hypothesis at a reduced significance level.] For example, if a trial is testing 20 hypotheses with a desired] `\(\small \alpha = 5\%\)`.smallest[, then the Bonferroni correction would test each individual hypothesis at] `\(\small \alpha^* = \alpha/20 = 5\% / 20 = 0.25\%\)`.smallest[. Therefore, .purple[it controls the familywise error rate at]] `\(\small \color{#6A5ACD}{\leq \alpha}\)`.
- .smallest[The Bonferroni correction can be .hi-turquoise[conservative] if there are a large number of tests, as it comes at the cost of reducing the power of the tests.]
- .smallest[Another more recent and less conservative method is the .hi-pink[False Discovery Rate (FDR)]. It provides less stringent control of Type I errors compared to the Bonferroni correction. Thus, the FDR has greater power, yet at the cost of increased numbers of Type I errors.]

---

# The one-way ANOVA

.smallest[To compare several means of different populations, we use a statistical method called the .hi-pink[(one-way) ANalysis Of VAriance (ANOVA)]] &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;. 

.smallest[We are interested in comparing means, but why is it an analysis of .purple[variance]?]
.pull-left[
&lt;img src="lecture2_files/figure-html/unnamed-chunk-19-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;img src="lecture2_files/figure-html/unnamed-chunk-20-1.svg" width="100%" style="display: block; margin: auto;" /&gt;
]

.footnote[.smallest[üëã There is also two-way ANOVA which analyzes the effect of two factors. For example, a customer wants to compare the lifetime of tires from different brands. In this case, he should use the one-way ANOVA, with brand as the only factor. However, if he also wants to consider a tire's heat resistance ability, then he should use the two-way ANOVA, with two factors: brand and heat resistance ability. Check out [more](https://en.wikipedia.org/wiki/Two-way_analysis_of_variance).]]

---

# The one-way ANOVA

.smallest[The one-way ANOVA makes similar assumptions as the two-sample t-test:]
- `\(\small J\)` .smallest[.hi-turquoise[independent] random samples are separately selected from each of these .hi-turquoise[distinct] populations. They can be of different sample sizes.]
- .smallest[The] `\(\small j^{th}\)` .smallest[population has a .pink[normal distribution] with unknown mean] `\(\small \mu_j\)`.
- .smallest[.purple[All the populations have the same variance], whose value is unknown.]

.smallest[Then the hypotheses for the one-way ANOVA can be specified as follows:]
`\begin{align}
&amp; \small H_0: \mu_1 = \mu_2 = \ldots = \mu_J \\
&amp; \small H_a: \text{not all of the } \mu_j \text{ are equal}
\end{align}`

.smallest[‚ö†Ô∏è Notice that the alternative says that the means are not all equal, which can be true because all the means are different or simply because one of them differs from the rest. So this is a more complex situation than comparing just two populations. .pink[If we reject the null hypothesis, we need to perform some further analysis to draw conclusions about which population means differ from which others and by how much.]]

---

# The one-way ANOVA table and F-test

.smallest[The one-way ANOVA relies on an F statistic to compare the variation among groups with the variation within groups. All calculations can be organized in an .hi-pink[ANOVA table]. More precisely, suppose we in total have] `\(\small N\)` .smallest[observations from] `\(\small J\)` .smallest[groups, where] `\(\small y_{ij}\)` .smallest[denotes the] `\(\small i^{th}\)` .smallest[observation from the] `\(\small j^{th}\)` .smallest[group, and] `\(\small n_j\)` .smallest[denotes the sample size of the] `\(\small j^{th}\)` .smallest[sample. Then the ANOVA table is given by:]

| Source        | Sum of squares  | Degrees of freedom  | Mean square                                  | F statistic                              |
| :-----------: |:---------------:| :------------------:| :-------------------------------------------:|:----------------------------------------:|
| Between       | `\(\text{SSB}\)`    | `\(\text{DFB} = J-1\)`  | `\(\text{MSB} = \frac{\text{SSB}}{\text{DFB}}\)` | `\(\text{F}=\frac{\text{MSB}}{\text{MSW}}\)` |
| Within        | `\(\text{SSW}\)`    | `\(\text{DFW} = N-J\)`  | `\(\text{MSW} = \frac{\text{SSW}}{\text{DFW}}\)` |                                          |
| Total         | `\(\text{SST}\)`    | `\(\text{DFT} = N-1\)`  |                                              |                                          |

`\begin{align}
&amp; \small \text{SSB} = \sum_{j=1}^J \sum_{i=1}^{n_j} (\bar{y_j} - \bar{y})^2 \;\;\; \text{SSW} = \sum_{j=1}^J \sum_{i=1}^{n_j} (y_{ij} - \bar{y_j})^2 \\
&amp; \small \text{SST} = \text{SSB} + \text{SSW} = \sum_{j=1}^J \sum_{i=1}^{n_j} (y_{ij} - \bar{y})^2
\end{align}`

---

# The one-way ANOVA table and F-test

- .smallest[.hi-pink[Sum of squares] are the sum of squared deviations presented in the data. As we can see, the total variation comes from two parts:: variation between groups and variation within groups.]
- .smallest[.hi-purple[Degrees of freedom] have the same relation, i.e.] `\(\small \text{DFT} = \text{DFB} + \text{DFW}\)`.smallest[.]
- .smallest[The one-way ANOVA relies on the .hi-turquoise[F statistic], which, when] `\(\small H_0\)` .smallest[is true, has an F distribution with two degrees of freedom,] `\(\small \text{DFB}\)` .smallest[and] `\(\small \text{DFW}\)`.smallest[. Therefore, it is also called the .hi-pink[F-test].]
- .smallest[Any differences among the group means tend to make the F statistic larger, and thus, smaller p-value. So in this sense, .purple[the F-test is always one-sided.]]
- .smallest[From the ANOVA table, we can clearly see how .turquoise[the value of the F statistic and the p-value depend on the sample sizes, the variation of the data within the groups, and the differences between the means.]]

---

# The one-way ANOVA: Example

.panelset[
.panel[.panel-name[Problem]
.smallest[Lamb's-quarter is a common weed that interferes with the growth of corn. A researcher collected 3 samples of corn yields (bushels per acre) from 3 plots, each of which are weeded such that there are 1, 3, 9 weeds per meter. .turquoise[The researcher believes that the corn yields follow normal distributions with the same variance.] He wants to test if the means of corn yields are all the same among these 3 groups with the following data:]
`\begin{align}
&amp; \small \text{Group 1 (1 weed/meter): } 163.7 \;\; 162.6 \;\; 155.4 \;\; 158.8 \;\; 156.1 \\
&amp; \small \text{Group 2 (3 weeds/meter): } 154 \;\; 152.7 \;\; 160.9 \;\; 157.5 \;\; 154.4 \\
&amp; \small \text{Group 3 (9 weeds/meter): } 149.9 \;\; 148.4 \;\; 139.5 \;\; 149.1 \;\; 145.2
\end{align}`
]
.panel[.panel-name[Test steps]
1. .smallest[.purple[Define hypotheses:]] 
`\begin{align}
&amp;\small H_0: \mu_1 = \mu_2 = \mu_3 \\
&amp;\small H_a: \text{not all three population means are equal}
\end{align}`
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 0.0464\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that not all the means of corn yields are the same among these 3 groups.]
]
.panel[.panel-name[`R` Code ]

```r
corn1 = c(163.7, 162.6, 155.4, 158.8, 156.1) 
corn2 = c(154, 152.7, 160.9, 157.5, 154.4)
corn3 = c(149.9, 148.4, 139.5, 149.1, 145.2)
corns = c(corn1, corn2, corn3)
groups = c(rep("Group 1", 5), rep("Group 2", 5), rep("Group 3", 5)) 

res_aov = aov(corns ~ groups)
summary(res_aov)
```

```
#&gt;             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
#&gt; groups       2  446.6  223.31   15.56 0.000464 ***
#&gt; Residuals   12  172.2   14.35                     
#&gt; ---
#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```
]
]

---

# Kruskal-Wallis test

- .smallest[The .hi-pink[Kruskal-Wallis test] is a test that can replace the ANOVA F-test. The assumption about data production (i.e. independent random samples from each population) remains important, but .pink[we can relax the normality and the same variance assumptions.] Indeed, we only need to assume that the response has a continuous distribution in each population.]
- .smallest[Just like the Wilcoxon tests for one and two samples, .purple[the Kruskal-Wallis test is particularly useful when there are outliers and/or when the normality condition cannot be satisfied.]]
- .smallest[The idea of the Kruskal-Wallis test is to rank all the responses from all groups together and then apply the one-way ANOVA to the .hi-turquoise[ranks] rather than to the original observations. Therefore, it is a .hi-turquoise[nonparametric test].]
- .smallest[In the simplest form, the Kruskal-Wallis test states the hypotheses in terms of .hi-pink[population median]. That is,]
`\begin{align}
&amp; \small H_0: \text{all populations have the same median} \\
&amp; \small H_a: \text{not all population medians are equal}
\end{align}`

---

# Revisit the corn yields example

.panelset[
.panel[.panel-name[Problem]
.smallest[Let's recall the previous corn yields example. The researcher wants to test if the means of corn yields are all the same among 3 groups that come from differently weeded plots. .turquoise[The researcher is not sure if the corn yields follow normal distributions with the same variance.] Recall the data as follows:]
`\begin{align}
&amp; \small \text{Group 1 (1 weed/meter): } 163.7 \;\; 162.6 \;\; 155.4 \;\; 158.8 \;\; 156.1 \\
&amp; \small \text{Group 2 (3 weeds/meter): } 154 \;\; 152.7 \;\; 160.9 \;\; 157.5 \;\; 154.4 \\
&amp; \small \text{Group 3 (9 weeds/meter): } 149.9 \;\; 148.4 \;\; 139.5 \;\; 149.1 \;\; 145.2
\end{align}`
]
.panel[.panel-name[Test steps]
1. .smallest[.purple[Define hypotheses:]] 
`\begin{align}
&amp;\small H_0: \text{median}_1 = \text{median}_2 = \text{median}_3 \\
&amp;\small H_a: \text{not all three population medians are equal}
\end{align}`
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 0.5248\%\)` .smallest[(see R code tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that not all the means of corn yields are the same among these 3 groups that are weeded differently.]
]
.panel[.panel-name[`R` Code ]

```r
corn1 = c(163.7, 162.6, 155.4, 158.8, 156.1) 
corn2 = c(154, 152.7, 160.9, 157.5, 154.4)
corn3 = c(149.9, 148.4, 139.5, 149.1, 145.2)
corns = c(corn1, corn2, corn3)
groups = c(rep("Group 1", 5), rep("Group 2", 5), rep("Group 3", 5)) 

kruskal.test(corns ~ groups)
```

```
#&gt; 
#&gt; 	Kruskal-Wallis rank sum test
#&gt; 
#&gt; data:  corns by groups
#&gt; Kruskal-Wallis chi-squared = 10.5, df = 2, p-value = 0.005248
```
]
]

---

# Summary

| Setting                     | Normal, no outliers  | Not normal, with outliers  |
| --------------------------- |----------------------| -------------------------- |
| One sample                  | One-sample t-test    | Wilcoxon signed rank test  |
| Two independent samples     | Two-sample t-test    | Wilcoxon rank sum test     |
| Several independent samples | One-way ANOVA F-test | Kruskal-Wallis test        |

- .smallest[With 2 or more samples, we have only discussed about tests for .hi-pink[comparison of means] as it is most often the case encountered in practice. Similar tests can be conducted to compare, for example, proportions or variances.]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
