<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Stéphane Guerrier &amp; Yuming Zhang" />
    <meta name="date" content="2020-12-18" />
    <link href="lecture1_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="lecture1_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="lecture1_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link href="lecture1_files/tile-view-0.2.4/tile-view.css" rel="stylesheet" />
    <script src="lecture1_files/tile-view-0.2.4/tile-view.js"></script>
    <link href="lecture1_files/panelset-0.2.4/panelset.css" rel="stylesheet" />
    <script src="lecture1_files/panelset-0.2.4/panelset.js"></script>
    <script src="lecture1_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="lecture1_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="lecture1_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to Statistics
## Part I: Introduction to Statistical Inference
### Stéphane Guerrier &amp; Yuming Zhang
### 18 December 2020

---









# Introduction

Welcome to the class ".hi-purple[Introduction to Statistics]"!

Throughout this class, we will use a platform called .hi-pink[Piazza] for the share of all the teaching materials and Q&amp;A. 

&lt;img src="pics/piazza.png" width="40%" style="display: block; margin: auto;" /&gt;

- Signup Link: [https://piazza.com/configure-classes/winter2020/sisu](https://piazza.com/configure-classes/winter2020/sisu)
- Access Code: .purple[statisfun]

---

# R and RStudio

.pull-left[
In this class, we will use the statistical software .hi-pink[R] together with the integrated development environment .hi-pink[R Studio], which you can download with the following: 

- Latest version of R: [https://cran.r-project.org/](https://cran.r-project.org/)
- Latest version of R Studio: [https://www.rstudio.com/](https://www.rstudio.com/)

.hi-purple[Note:] You cannot use RStudio without having installed R on your computer.
]

.pull-right[

&lt;img src="pics/r_first_then.png" width="100%" style="display: block; margin: auto;" /&gt;

]

---

# What is statistics?

.pull-left[
.smaller[.hi-pink[Statistics] is a science that uses mathematics and computer science to deal with the collection, analysis, interpretation, and presentation of masses of numerical data. Informally, it is the .pink[science of learning from data].]
&lt;img src="pics/stat.jpeg" width="90%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [luminousmen](luminousmen.com)]
]

.pull-right[
.smaller[.hi-purple[Statistics] is a crucial part of our life. However, .purple[statistical methods are often consciously (or not) misused]. This can lead to contradictory studies and conclusions (as seen during the current COVID-19 pandemic).]

&lt;img src="pics/data-torture.png" width="80%" style="display: block; margin: auto;" /&gt;

.tiny[Source: [Atoz Markets](https://atozmarkets.com/news/untold-reality-of-p-hacking-in-finance/)]
]

---

# How can statistics be useful?

.smallest[Statistics can be used (among others) to

1. .purple[Visualize data] (e.g. propagation of COVID-19 in different countries).
2. .purple[Understand and interpret data] (e.g. main causes of cancer). 
3. .purple[Assess the validity of a hypothesis] (e.g. is a drug working?).
4. .purple[Make predictions] (e.g. predicting unemployment or risk indices).]

.smallest[Learning more about statistics allows to ]

1. .smallest[Better understand .pink[arguments based on data.]]
2. .smallest[Be able to apply .pink[critical thinking] about .pink[statistics used as evidence].]
3. .smallest[Understand how statistical associations are used to .pink[evaluate claims (hypotheses)] and .pink[assess causal connections.]]  

.smallest[.purple[Understanding and knowing how to interpret statistical analyses is therefore becoming an increasingly vital skill.]]

---

# Simpson's Paradox

.pull-left[.smallest[.hi-pink[Statistical analysis can be tricky.] Here we give an example of a study of gender bias among graduate school admissions to University of California, Berkeley, for the fall of 1973.]

&lt;img src="lecture1_files/figure-html/unnamed-chunk-4-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
.smallest[
The data show that .purple[among 8,442 men applicants 44% were admitted] while .pink[among 4,321 women applicants only 35% were admitted]. The overall admission rate was around 41%. The difference is quite large (9%) and it is a large sample with 12,763 applicants, so it is unlikely that this is due to chance. Therefore, the data suggest that .purple[men applying were more likely to be admitted than women].

However, when people looked more into the data, they found that this conclusion is actually completely incorrect. In fact, a correct analysis showed that .pink["small but statisticall significant bias in favor of women"]. But why? 😮
]
]

---

# Simpson's Paradox

.pull-left[

&lt;img src="lecture1_files/figure-html/unnamed-chunk-5-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="lecture1_files/figure-html/unnamed-chunk-6-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

- .smallest[Men applicants tended to apply for "easy" departments, i.e. departments that had high admission rates.] 
- .smallest[Women applicants tended to apply to "hard" departments, i.e. departments that had low admission rates.]  
- .smallest[So it turns out that most of the departments actually had a slightly higher success rate for women.]
- .smallest[This phenomenon is known as .hi-purple[Simpson's Paradox]. ]

---

# How does it work?

.smallest[
- Statistical methods are based on several fundamental concepts, the most central of which is to consider the information available (in the form of data) resulting from a .purple[random process].
- As such, the data represent a .hi-pink[random sample] of a totally or conceptually accessible .hi-pink[population].
- Then, .purple[statistical inference] allows to infer the properties of a population based on the observed sample. This includes deriving estimates and testing hypotheses.
]

&lt;img src="pics/sampling.png" width="45%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [luminousmen](luminousmen.com)]


---

# Outline

In this class, we plan to cover the following topics: 

- Introduction to .pink[statistical inference] (concepts of random variables, confidence interval and p-values).
- Introduction to the .purple[statistical software R].
- .pink[Tests for comparing the mean of two groups] (descriptive analysis, t-test, rank-based methods).
- .purple[Tests for comparing the mean of multiple groups] (descriptive analysis, ANOVA and non-parametric counterparts, discussion on multiple testing).
- Introduction to .pink[regression] (correlation vs causality, descriptive analysis, linear regression and going beyond linear regression).
- .purple[Pitfalls] for statistical analysis and remedies (p-hacking/HARKing and how to avoid it, replicability crisis).

---

# Population and Sample - Example

.smallest[To fix ideas we will consider a simple example. The 2020 United States presidential election was the 59th quadrennial presidential election, held on November 3, 2020. According to the latest estimates, .hi.pink[Biden's team received 51.3% of the votes while Trump's received 46.8%] &lt;sup&gt;.smallest[👋]&lt;/sup&gt;. Naturally, the result of American elections is not determined by the popular vote but suppose that we were interested in collecting data .hi-purple[before the vote] to assess if Biden's team will receive more than 50% of the votes].

&lt;img src="pics/trump2.png" width="80%" style="display: block; margin: auto;" /&gt;

.tiny[Source: Adapted from [fivethirtyeight.](https://projects.fivethirtyeight.com/trump-biden-election-map/)]

.footnote[.smallest[👋 More details on the results can be found [here](https://en.wikipedia.org/wiki/2020_United_States_presidential_election).]]

---

# Population and Sample - Example

.pull-left[.smaller[In this example, we will make the .purple[following assumptions for simplicity]:

- The American population of voters is composed of 1200 individuals (616 for Biden, 561 for Trump and 23 independents).
- We can perfectly sample the population (everyone is available, no double sampling, and the sampling is random).
- People don't change their mind and they don't lie.
]]

.pull-right[

&lt;img src="pics/pop.jpg" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Proportion Estimation

Suppose we ask `\(n\)` voters for which candidate (Biden, Trump or independent) they intend to vote in order to estimate the proportion of voters for Biden. For that we define the .hi.purple[random variables] `\(X_1, ..., X_n\)` where `\(X_i\)` is defined as:

.saller[
.center[
`\(
X_i = \left\{
	\begin{array}{ll}
		1  &amp; \mbox{if voter } i \mbox{ intends to vote for Biden}\\
		0 &amp; \mbox{otherwise.}
	\end{array}
\right.
\)`
]
]


The random variables `\(X_1, ..., X_n\)` are called a (random) .hi.purple[sample] and we refer to `\(n\)` as the .hi.purple[sample size]. Let `\(p\)` denote the (true) proportion of voters for Biden (which in this case is 51.3%), we then write


$$
`\begin{align}
\color{#e64173}{\Pr \Big(} {X_i = 1} \color{#e64173}{\Big)} = p,
\end{align}`
$$


where `\(\color{#e64173}{\Pr (} A \color{#e64173}{)}\)` denotes the .pink[probability] of the .purple[event] `\(A\)`.

---

# Proportion Estimation

Using the random variables `\(X_1, ..., X_n\)` we can define an .hi.purple[estimator] of `\(p\)`, which we often write as `\(\hat{p}\)` and is given by


`$$\hat{p} = \frac{1}{n} \sum_{i=1}^n X_i = \frac{\color{#e64173}{m}}{\color{#6A5ACD}{n}},$$`


where `\(\color{#e64173}{m}\)` denotes the number of voters in our sample in favor of Biden, and `\(\color{#6A5ACD}{n}\)` is the sample size (as described previously).

An estimator is defined as a function of the data (i.e. `\(X_1, ..., X_n\)`), and therefore, theoretically any function of `\(X_1, ..., X_n\)` can be an estimator. However, in this case `\(\hat{p}\)` is the best possible estimator of `\(p\)` &lt;sup&gt;.smallest[👋]&lt;/sup&gt; and therefore it is not useful (in this case) to search for better estimators.

.footnote[.smallest[👋] More precisely, this estimator is unbiased [(more info.)](https://en.wikipedia.org/wiki/Bias_of_an_estimator) and has the smallest possible variance [(more info.)](https://en.wikipedia.org/wiki/Variance) as it attains the Cramér–Rao bound [(more info.)](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound).]
 
---

# Population and Sample - Example

.pull-left[
.smallest[
Consider a sample of `\(n = 10\)` voters (randomly chosen from the population) as shown here 👉. In this case, we have 5 voters for Biden and 5 for Trump. We say that `$$x_1 = 1, ..., x_5 = 1, x_6 = 0, ..., x_{10} = 0$$` are .hi.purple[realizations] of the random variables `\(X_1, ..., X_{10}\)`.

We can now compute our estimator on the observed data (i.e. the realizations) and we obtain `\(\hat{p} = 0.5\)`. Therefore, .pink[our best guess] based on the available data is that 50% of the voters will vote for Biden. Unfortunately, this doesn't really help us. So let's try with a bigger sample size... say `\(n = 40\)`.
]]

.pull-right[

&lt;img src="pics/sample1.jpg" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Population and Sample - Example

&lt;img src="pics/sample3.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Population and Sample - Example

.center[![](GIF/sample.gif)]

---

# Population and Sample - Example

&lt;img src="pics/sample_n2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Population and Sample - Example

&lt;img src="pics/sample_n.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---

# Population and Sample - Example

- In our example, we are interested in knowing if `\(p\)`, a .pink[population-level quantity], is bigger or smaller than 50%. Unfortunately, `\(p\)` is generally unknown as we cannot access the whole population (otherwise let's not bother with Statistics! 🤪). Therefore, we use `\(\hat{p}\)` instead, a .purple[sample-dependent quantity].
- However, as we can see, `\(\hat{p}\)` is .turquoise[random] in the sense that it can change depending on the collected sample (e.g. we get different answers when `\(n = 200\)`, where Trump is leading, and when `\(n = 600\)`, where Biden is leading). 
- To address this issue, we need to assess the .hi.pink[uncertainty] of `\(\hat{p}\)` (i.e. assess how different `\(\hat{p}\)` and `\(p\)` can be).
- Statistics can provides us many tools allowing to determine uncertainty as well as the associated .pink[decision-making risks].

---

# How to measure uncertainty?

Uncertainty can be measured in many different ways. A common approach (in statistics) is to use .hi-purple[confidence intervals], which rely on the .hi.pink[Central Limit Theorem (CLT)] that states:

.center[.turquoise["The sampling distribution of the sample mean approaches to a normal distribution as the sample size gets larger."]]

Loosely speaking, we can translate the CLT as 

`$$\bar{X} = \frac{1}{n} \sum_{i = 1}^n X_i \color{#e64173}{\overset{\cdot}{\sim}} \color{#6A5ACD}{\mathcal{N}(\mu, \sigma^2)},$$` 

where `\(\color{#6A5ACD}{\mathcal{N}(\mu, \sigma^2)}\)` denotes a normal distribution with mean `\(\mu\)` and variance `\(\sigma^2\)` (typically computed using the data)&lt;sup&gt;.smallest[👋]&lt;/sup&gt;. Here `\(\bar{X}\)` denotes the sample mean and `\(\color{#e64173}{\overset{\cdot}{\sim}}\)` represents ".pink[approximately distributed as]". 

.footnote[.smallest[👋] Check out [expected value](https://en.wikipedia.org/wiki/Expected_value) and [variance](https://en.wikipedia.org/wiki/Variance).]

---

# How to measure uncertainty?

.smallest[In our example, we have] `\(\small \hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(p, \frac{p(1-p)}{n}\Bigg).\)`

- .smallest[How to understand the practical implications of the CLT?]
- .smallest[It essentially implies that when a measure is the average (or the sum) of various measures, then its distribution goes to a normal distribution provided sufficient data collected. (e.g. the height of an adult can be thought of as the sum of genetics, nutrients, life style ...)]
- .smallest[A normal distribution looks like:]

&lt;img src="pics/normal.png" width="50%" style="display: block; margin: auto;" /&gt;

---

# Distribution of heights

&lt;img src="pics/distribution-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt1.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt3.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

.center[![](GIF/sample_clt.gif)]

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt_n.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

.center[![](GIF/sample_clt2.gif)]

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt_n2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

People have used .pink[the Galton Board] as a practical device to demonstrate the CLT, in particular that with sufficient sample size the binomial distribution approximates a normal distribution.

&lt;div align="center"&gt;
&lt;iframe width="684" height="381" src="https://www.youtube.com/watch?v=Vo9Esp1yaC8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

---

# Confidence Intervals

Now that we learn about CLT, how can we use it to construct .hi-purple[confidence intervals]? 

- .smaller[Confidence intervals correspond to .pink[a range of values that are likely to include the population value with a certain level of confidence]. The level of confidence is a probability expressed as a percentage (%).] 
- .smaller[In our example, we are interested in the true (population) proportion of voters in favor of Biden (51.3%). Using our sample of] `\(\small n=200\)` .smaller[, we had] `\(\small m =95\)` .smaller[and we can construct the following 95% confidence interval]:

.pull-left[
&lt;img src="pics/ci.jpg" width="90%" style="display: block; margin: auto;" /&gt;
]

.smaller[.pull-right[
So what does it mean? 🤔 It means that with a .hi-purple[probability of 95%], the true proportion of voters for Biden (51.3% in this case) is between 40.58% and 54.42%.]
]


---

# Confidence Intervals

How is this confidence interval computed? We recall that by CLT, 

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(p, \frac{p(1-p)}{n}\Bigg).$$`
However, as we .hi.purple[do not know] the true value of `\(p\)` in practice, we replace it with the .hi.purple[best guess] we have, which is `\(\hat{p}\)`. We then can write

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(\color{#e64173}{\hat{p}}, \color{#6A5ACD}{\frac{\hat{p}(1-\hat{p})}{n}}\Bigg).$$`

The `\(1-\alpha\)` confidence interval for `\(p\)` is then given by

`$$\color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}.$$`

But what is `\(Z_{1-\alpha/2}\)`? 🤓

---

# Confidence Intervals

`\(Z_{1-\alpha/2}\)` corresponds to the `\(1-\alpha/2\)` quantile of a standard normal distribution `\(\mathcal{N}(0,1)\)`, that is, 

.center[ 
`\(Z_{1-\alpha/2}\)` is such that `\(\Pr(Z \leq Z_{1-\alpha/2}) = 1-\alpha/2\)` where `\(Z \sim \mathcal{N}(0,1)\)`.
]

.pull-left[

&lt;img src="pics/standard_normal.png" width="70%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
- For 90% confidence interval, `\(Z_{0.95} \approx 1.64\)`. 
- .pink[For 95% confidence interval,] `\(\color{#e64173}{Z_{0.975} \approx 1.96}\)`.pink[.]
- For 99% confidence interval, `\(Z_{0.995} \approx 2.58\)`. 
]
---

# Confidence Intervals

Therefore, a confidence interval corresponds to a range of values that contains the true unknown population-level quantity we are considering with a probability of approximately `\(1-\alpha\)` (typically 95%).

Basically, we have

`$$\Pr \left(p \in \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \right) \approx 1-\alpha.$$`

⚠️ This means that a fraction of `\(100\times\alpha\)`% of confidence intervals .hi.pink[don't include] `\(p\)`. 

---

# Confidence Intervals

.center[![](GIF/sample_clt3.gif)]

---

# Confidence Intervals

&lt;img src="pics/ci2.jpg" width="90%" style="display: block; margin: auto;" /&gt;

---

# How to compute confidence intervals

.panelset[
.panel[.panel-name[Example]
.smallest[Previously, we said that in a sample of] `\(n\)`=200, we had *m* = 95. In this case, we mentioned that (40.45%, 54.65%) was a 95% confidence interval. But how are these numbers computed?

.smallest[Therefore, we have]

$$ \small \color{#e64173}{\hat{p}} = \frac{m}{n} = \frac{13173}{25468} \approx \color{#e64173}{51.728\%}.$$
.smallest[Then, we have]

`$$\small\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#6A5ACD}{0.003131}.$$`
.smallest[To obtain a 95\% confidence interval we used] `\(\small Z_{1-\alpha/2} = Z_{0.975} \approx 1.96\)` .smallest[ and we get]

`$$\small \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#e64173}{51.728} \pm 1.96 \times \color{#6A5ACD}{0.003131} = (51.11\%, 52.34\%).$$`

]
.panel[.panel-name[`R` Code - 💪]

```r
n = 25468                  # Sample size
m = 13173                  # Number of boys
alpha = 0.05               # Confidence level (1-alpha)
p_hat = m/n                # Estimated proportion

# Compute CI
Z = qnorm(1 - alpha/2)
delta = sqrt(p_hat*(1 - p_hat)/n)
CI = p_hat + c(-1, +1)*Z*delta
print(paste("The estimated proportion is ", round(100*p_hat, 2), "%", sep = ""))
```

```
#&gt; [1] "The estimated proportion is 51.72%"
```

```r
print(paste("A ", (1 - alpha)*100, "% confidence interval is given by (",
            round(100*CI[1], 2), "%, ", round(100*CI[2], 2), "%)", sep = ""))
```

```
#&gt; [1] "A 95% confidence interval is given by (51.11%, 52.34%)"
```
]

.panel[.panel-name[`R` Code - 🤖]


```r
n = 25468                  # Sample size
m = 13173                  # Number of boys
prop.test(x = m, n = n)
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  m out of n, null probability 0.5
#&gt; X-squared = 30.2, df = 1, p-value = 3.897e-08
#&gt; alternative hypothesis: true p is not equal to 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.5110785 0.5233910
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5172373
```
]
]


# Confidence Interval - Example 2

add an interdisciplinary example

---

# ⚠️ Take home message

- Since the data is available through sampling, it is .hi-purple[random]. .pink[Therefore, a decision or prediction can never be made with certainty!]
- The only certainty one can have is that, for example, a proportion will always be included in the interval from 0% to 100%. .hi-purple[However, this is neither informative nor useful] and it does not even depend on the data.
- There exists a trade-off between .hi-pink[risk] as measured by  `\(1-\alpha\)` (typically 95%) the confidence level, and the .hi-pink[precision of the conclusion] as measured, for example, by the confidence interval length.
- Moreover, the larger the sample size, the more precise the conclusion, for the same confidence level.
- Therefore, .purple[every decision based on statistical methods has a risk and how much risk is acceptable depends on the context] (e.g. safety in airplanes vs which soft drink tastes better).

# Are there more 👦 than 👧?

.panelset[
.panel[.panel-name[Animation]
.smallest[An American found 13,173 boys were born among 25,468 newborn children. Is this sample an evidence that the birth of boys may be more common than the birth of girls in the entire population?] .smallest[So, we have] `\(\small n = 25,468\)` .smallest[and] `\(\small m = 13,173\)`. .smallest[Therefore, we have]

$$ \small \color{#e64173}{\hat{p}} = \frac{m}{n} = \frac{13173}{25468} \approx \color{#e64173}{51.728\%}.$$
.smallest[Then, we have]

`$$\small\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#6A5ACD}{0.003131}.$$`
.smallest[To obtain a 95\% confidence interval we used] `\(\small Z_{1-\alpha/2} = Z_{0.975} \approx 1.96\)` .smallest[ and we get]

`$$\small \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#e64173}{51.728} \pm 1.96 \times \color{#6A5ACD}{0.003131} = (51.11\%, 52.34\%).$$`

]
.panel[.panel-name[`R` Code - 💪]

```r
n = 25468                  # Sample size
m = 13173                  # Number of boys
alpha = 0.05               # Confidence level (1-alpha)
p_hat = m/n                # Estimated proportion

# Compute CI
Z = qnorm(1 - alpha/2)
delta = sqrt(p_hat*(1 - p_hat)/n)
CI = p_hat + c(-1, +1)*Z*delta
print(paste("The estimated proportion is ", round(100*p_hat, 2), "%", sep = ""))
```

```
#&gt; [1] "The estimated proportion is 51.72%"
```

```r
print(paste("A ", (1 - alpha)*100, "% confidence interval is given by (",
            round(100*CI[1], 2), "%, ", round(100*CI[2], 2), "%)", sep = ""))
```

```
#&gt; [1] "A 95% confidence interval is given by (51.11%, 52.34%)"
```
]

.panel[.panel-name[`R` Code - 🤖]


```r
n = 25468                  # Sample size
m = 13173                  # Number of boys
prop.test(x = m, n = n)
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  m out of n, null probability 0.5
#&gt; X-squared = 30.2, df = 1, p-value = 3.897e-08
#&gt; alternative hypothesis: true p is not equal to 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.5110785 0.5233910
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5172373
```
]
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
