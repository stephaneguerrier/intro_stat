<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="Stéphane Guerrier &amp; Yuming Zhang" />
    <meta name="date" content="2020-12-18" />
    <link href="lecture1_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="lecture1_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="lecture1_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to Statistics
## Part I: Introduction to Statistical Inference
### Stéphane Guerrier &amp; Yuming Zhang
### 18 December 2020

---









# Introduction

Welcome to the class ".hi-purple[Introduction to Statistics]"!

Throughout this class, we will use a platform called .hi-pink[Piazza] for the share of all the teaching materials and Q&amp;A. 

&lt;img src="pics/piazza.png" width="40%" style="display: block; margin: auto;" /&gt;

- Signup Link: [https://piazza.com/configure-classes/winter2020/sisu](https://piazza.com/configure-classes/winter2020/sisu)
- Access Code: .purple[statisfun]

---

# R and RStudio

.pull-left[
In this class, we will use the statistical software .hi-pink[R] together with the integrated development environment .hi-pink[R Studio], which you can download with the following: 

- Latest version of R: [https://cran.r-project.org/](https://cran.r-project.org/)
- Latest version of R Studio: [https://www.rstudio.com/](https://www.rstudio.com/)

.hi-purple[Note:] You cannot use RStudio without having installed R on your computer.
]

.pull-right[

&lt;img src="pics/r_first_then.png" width="100%" style="display: block; margin: auto;" /&gt;

]

---

# What is statistics?

.pull-left[
.smaller[.hi-pink[Statistics] is a science that uses mathematics and computer science to deal with the collection, analysis, interpretation, and presentation of masses of numerical data. Informally, it is the .pink[science of learning from data].]
&lt;img src="pics/stat.jpeg" width="90%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [luminousmen](luminousmen.com)]
]

.pull-right[
.smaller[.hi-purple[Statistics] is a crucial part of our life. However, .purple[statistical methods are often consciously (or not) misused]. This can lead to contradictory studies and conclusions (as seen during the current COVID-19 pandemic).]

&lt;img src="pics/data-torture.png" width="80%" style="display: block; margin: auto;" /&gt;

.tiny[Source: [Atoz Markets](https://atozmarkets.com/news/untold-reality-of-p-hacking-in-finance/)]
]

---

# How can statistics be useful?

.smallest[Statistics can be used (among others) to

1. .purple[Visualize data] (e.g. propagation of COVID-19 in different countries).
2. .purple[Understand and interpret data] (e.g. main causes of cancer). 
3. .purple[Assess the validity of a hypothesis] (e.g. is a drug working?).
4. .purple[Make predictions] (e.g. predicting unemployment or risk indices).]

.smallest[Learning more about statistics allows to ]

1. .smallest[Better understand .pink[arguments based on data.]]
2. .smallest[Be able to apply .pink[critical thinking] about .pink[statistics used as evidence].]
3. .smallest[Understand how statistical associations are used to .pink[evaluate claims (hypotheses)] and .pink[assess causal connections.]]  

.smallest[.purple[Understanding and knowing how to interpret statistical analyses is therefore becoming an increasingly vital skill.]]

---

# Simpson's Paradox

.pull-left[.smallest[.hi-pink[Statistical analysis can be tricky.] Here we give an example of a study of gender bias among graduate school admissions to University of California, Berkeley, for the fall of 1973.]

&lt;img src="lecture1_files/figure-html/unnamed-chunk-4-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
.smallest[
The data show that .purple[among 8,442 men applicants 44% were admitted] while .pink[among 4,321 women applicants only 35% were admitted]. The overall admission rate was around 41%. The difference is quite large (9%) and it is a large sample with 12,763 applicants, so it is unlikely that this is due to chance. Therefore, the data suggest that .purple[men applying were more likely to be admitted than women].

However, when people looked more into the data, they found that this conclusion is actually completely incorrect. In fact, a correct analysis showed that .pink["small but statisticall significant bias in favor of women"]. But why? 😮
]
]

---

# Simpson's Paradox

.pull-left[

&lt;img src="lecture1_files/figure-html/unnamed-chunk-5-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="lecture1_files/figure-html/unnamed-chunk-6-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

- .smallest[Men applicants tended to apply for "easy" departments, i.e. departments that had high admission rates.] 
- .smallest[Women applicants tended to apply to "hard" departments, i.e. departments that had low admission rates.]  
- .smallest[So it turns out that most of the departments actually had a slightly higher success rate for women.]
- .smallest[This phenomenon is known as .hi-purple[Simpson's Paradox]. ]

---

# How does it work?

.smallest[
- Statistical methods are based on several fundamental concepts, the most central of which is to consider the information available (in the form of data) resulting from a .purple[random process].
- As such, the data represent a .hi-pink[random sample] of a totally or conceptually accessible .hi-pink[population].
- Then, .purple[statistical inference] allows to infer the properties of a population based on the observed sample. This includes deriving estimates and testing hypotheses.
]

&lt;img src="pics/sampling.png" width="45%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [luminousmen](luminousmen.com)]


---

# Outline

In this class, we plan to cover the following topics: 

- Introduction to .pink[statistical inference] (concepts of random variables, confidence interval and p-values).
- Introduction to the .purple[statistical software R].
- .pink[Tests for comparing the mean of two groups] (descriptive analysis, t-test, rank-based methods).
- .purple[Tests for comparing the mean of multiple groups] (descriptive analysis, ANOVA and non-parametric counterparts, discussion on multiple testing).
- Introduction to .pink[regression] (correlation vs causality, descriptive analysis, linear regression and going beyond linear regression).
- .purple[Pitfalls] for statistical analysis and remedies (p-hacking/HARKing and how to avoid it, replicability crisis).

---

# Population and Sample - Example

.smallest[To fix ideas we will consider a simple example. The 2020 United States presidential election was the 59th quadrennial presidential election, held on November 3, 2020. According to the latest estimates, .hi.pink[Biden's team received 51.3% of the votes while Trump's received 46.8%] &lt;sup&gt;.smallest[👋]&lt;/sup&gt;. Naturally, the result of American elections is not determined by the popular vote but suppose that we were interested in collecting data .hi-purple[before the vote] to assess if Biden's team will receive more than 50% of the votes].

&lt;img src="pics/trump2.png" width="80%" style="display: block; margin: auto;" /&gt;

.tiny[Source: Adapted from [fivethirtyeight.](https://projects.fivethirtyeight.com/trump-biden-election-map/)]

.footnote[.smallest[👋 More details on the results can be found [here](https://en.wikipedia.org/wiki/2020_United_States_presidential_election).]]

---

# Population and Sample - Example

.pull-left[.smaller[In this example, we will make the .purple[following assumptions for simplicity]:

- The American population of voters is composed of 1200 individuals (616 for Biden, 561 for Trump and 23 independents).
- We can perfectly sample the population (everyone is available, no double sampling, and the sampling is random).
- People don't change their mind and they don't lie.
]]

.pull-right[

&lt;img src="pics/pop.jpg" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Proportion Estimation

Suppose we ask `\(n\)` voters for which candidate (Biden, Trump or independent) they intend to vote in order to estimate the proportion of voters for Biden. For that we define the .hi.purple[random variables] `\(X_1, ..., X_n\)` where `\(X_i\)` is defined as:

.saller[
.center[
`\(
X_i = \left\{
	\begin{array}{ll}
		1  &amp; \mbox{if voter } i \mbox{ intends to vote for Biden}\\
		0 &amp; \mbox{otherwise.}
	\end{array}
\right.
\)`
]
]


The random variables `\(X_1, ..., X_n\)` are called a (random) .hi.purple[sample] and we refer to `\(n\)` as the .hi.purple[sample size]. Let `\(p\)` denote the (true) proportion of voters for Biden (which in this case is 51.3%), we then write


$$
`\begin{align}
\color{#e64173}{\Pr \Big(} {X_i = 1} \color{#e64173}{\Big)} = p,
\end{align}`
$$


where `\(\color{#e64173}{\Pr (} A \color{#e64173}{)}\)` denotes the .pink[probability] of the .purple[event] `\(A\)`.

---

# Proportion Estimation

Using the random variables `\(X_1, ..., X_n\)` we can define an .hi.purple[estimator] of `\(p\)`, which we often write as `\(\hat{p}\)` and is given by


`$$\hat{p} = \frac{1}{n} \sum_{i=1}^n X_i = \frac{\color{#e64173}{m}}{\color{#6A5ACD}{n}},$$`


where `\(\color{#e64173}{m}\)` denotes the number of voters in our sample in favor of Biden, and `\(\color{#6A5ACD}{n}\)` is the sample size (as described previously).

An estimator is defined as a function of the data (i.e. `\(X_1, ..., X_n\)`), and therefore, theoretically any function of `\(X_1, ..., X_n\)` can be an estimator. However, in this case `\(\hat{p}\)` is the best possible estimator of `\(p\)` &lt;sup&gt;.smallest[👋]&lt;/sup&gt; and therefore it is not useful (in this case) to search for better estimators.

.footnote[.smallest[👋] More precisely, this estimator is unbiased [(more info.)](https://en.wikipedia.org/wiki/Bias_of_an_estimator) and has the smallest possible variance [(more info.)](https://en.wikipedia.org/wiki/Variance) as it attains the Cramér–Rao bound [(more info.)](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound).]
 
---

# Population and Sample - Example

.pull-left[
.smallest[
Consider a sample of `\(n = 10\)` voters (randomly chosen from the population) as shown here 👉. In this case, we have 5 voters for Biden and 5 for Trump. We say that `$$x_1 = 1, ..., x_5 = 1, x_6 = 0, ..., x_{10} = 0$$` are .hi.purple[realizations] of the random variables `\(X_1, ..., X_{10}\)`.

We can now compute our estimator on the observed data (i.e. the realizations) and we obtain `\(\hat{p} = 0.5\)`. Therefore, .pink[our best guess] based on the available data is that 50% of the voters will vote for Biden. Unfortunately, this doesn't really help us. So let's try with a bigger sample size... say `\(n = 40\)`.
]]

.pull-right[

&lt;img src="pics/sample1.jpg" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Population and Sample - Example

&lt;img src="pics/sample3.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Population and Sample - Example

.center[![](GIF/sample.gif)]

---

# Population and Sample - Example

&lt;img src="pics/sample_n2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Population and Sample - Example

&lt;img src="pics/sample_n.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---

# Population and Sample - Example

- In our example, we are interested in knowing if `\(p\)`, a .pink[population-level quantity], is bigger or smaller than 50%. Unfortunately, `\(p\)` is generally unknown as we cannot access the whole population (otherwise let's not bother with Statistics! EMOJI). Therefore, we use `\(\hat{p}\)` instead, a .purple[sample-dependent quantity].
- However, as we can see, `\(\hat{p}\)` is .turquoise[random] in the sense that it can change depending on the collected sample (e.g. we get different answers when `\(n = 200\)`, where Trump is leading, and when `\(n = 600\)`, where Biden is leading). 
- To address this issue, we need to assess the .hi.pink[uncertainty] of `\(\hat{p}\)` (i.e. assess how different `\(\hat{p}\)` and `\(p\)` can be).
- Statistics can provides us many tools allowing to determine uncertainty as well as the associated .pink[decision-making risks].

---

# How to measure uncertainty?

Uncertainty can be measured in many different ways. A common approach (in statistics) is to use .hi-purple[confidence intervals], which rely on the .hi.pink[Central Limit Theorem (CLT)] that states:

.center[.turquoise["The sampling distribution of the sample mean approaches to a normal distribution as the sample size gets larger."]]

Loosely speaking, we can translate the CLT as 

`$$\bar{X} = \frac{1}{n} \sum_{i = 1}^n X_i \color{#e64173}{\overset{\cdot}{\sim}} \color{#6A5ACD}{\mathcal{N}(\mu, \sigma^2)},$$` 

where `\(\color{#6A5ACD}{\mathcal{N}(\mu, \sigma^2)}\)` denotes a normal distribution with mean `\(\mu\)` and variance `\(\sigma^2\)` (typically computed using our data)&lt;sup&gt;.smallest[👋]&lt;/sup&gt;. Here `\(\bar{X}\)` denotes the sample mean and `\(\color{#e64173}{\overset{\cdot}{\sim}}\)` represents ".pink[approximately distributed as]". 

.footnote[.smallest[👋] Check out [expected value](https://en.wikipedia.org/wiki/Expected_value) and [variance](https://en.wikipedia.org/wiki/Variance).]

---

# How to measure uncertainty?

In our example, we have `$$\hat{p} \overset{\cdot}{\sim} N(p, \frac{p(1-p)}{n})$$`. 

SO WHAT DOES IT MEAN... WHEN SOMETHING IS ANAVERAGE OF LOTS OF STUFF THE DISTRBUTION GOES TO A NORMAL

HOW DOES A NORMAL LOOK LIKE ... ADD AN IMAGE

---

# Distribution of heights

&lt;img src="pics/distribution-1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt1.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt3.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

.center[![](GIF/sample_clt.gif)]

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt_n.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

.center[![](GIF/sample_clt2.gif)]

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt_n2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Confidence Intervals

Now that we learn about CLT, how can we use it to construct .hi-purple[confidence intervals]? 

- .smaller[Confidence intervals correspond to .pink[a range of values that are likely to include the population value with a certain level of confidence]. The level of confidence is a probability expressed as a percentage (%).] 
- .smaller[In our example, we are interested in the true (population) proportion of voters in favor of Biden (51.3%). Using our sample of *n*=200, we had *m* = 95 and we can construct the following 95% confidence interval]:

.pull-left[
&lt;img src="pics/ci.jpg" width="90%" style="display: block; margin: auto;" /&gt;
]

.smaller[.pull-right[
So what does it mean? 🤔 It means that with a .hi-purple[probability of 95%], the true proportion of voters for Biden (51.3% in this case) is between 40.45% and 54.65%.]
]


---

# Confidence Intervals

How is this confidence interval computed? We recall that by CLT, 

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(p, \frac{p(1-p)}{n}\Bigg).$$`
However, as we .hi.purple[do not know] the true value of `\(p\)` in practice, we replace it with the .hi.purple[best guess] we have, which is `\(\hat{p}\)`. We then can write

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(\color{#e64173}{\hat{p}}, \color{#6A5ACD}{\frac{\hat{p}(1-\hat{p})}{n}}\Bigg).$$`

The `\(1-\alpha\)` confidence interval for `\(p\)` is then given by

`$$\color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}.$$`

But what is `\(Z_{1-\alpha/2}\)`? 🤓

---

# Confidence Intervals

`\(Z_{1-\alpha/2}\)` corresponds to the `\(1-\alpha/2\)` quantile of a standard normal distribution `\(\mathcal{N}(0,1)\)`, that is, 

.center[ 
`\(Z_{1-\alpha/2}\)` is such that `\(\Pr(Z \leq Z_{1-\alpha/2}) = 1-\alpha/2\)` where `\(Z \sim \mathcal{N}(0,1)\)`.
]

.pull-left[

&lt;img src="pics/standard_normal.png" width="70%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
- For 90% confidence interval, `\(Z_{0.95} \approx 1.64\)`. 
- .purple[For 95% confidence interval,] `\(\color{#6A5ACD}{Z_{0.975} \approx 1.96}\)`.purple[.]
- For 99% confidence interval, `\(Z_{0.995} \approx 2.58\)`. 
]
---

# Confidence Intervals

Therefore, a confidence intervals corresponds to a range of values that contains the true unknown population level quantity we are considering with a probability of approximately `\(1-\alpha\)` (typically 95%).

Basically, we have

`$$\Pr \left(p \in \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \right) \approx 1-\alpha.$$`

⚠️ This means that a fraction of `\(100\times\alpha\)`% of confidence intervals .hi.pink[don't include] `\(p\)`. 

.purple[Therefore, conclusions can never be made with certainty!]

---

# Confidence Interval - Example 2

add an interdisciplinary example

---

# ⚠️ Take home message

- Since the data is available through sampling, it is .hi-purple[random]. .pink[Therefore, a decision or prediction can never be made with certainty!]
- The only certainty one can have is that, for example, a proportion will always be included in the interval from 0% to 100%. .hi-purple[However, this is neither informative nor useful] and it does not even depend on the data.
- There exists a trade-off between .hi-pink[risk] as measured by  `\(1-\alpha\)` (typically 95%) the confidence level, and the .hi-pink[precision of the conclusion] as measured, for example, by the confidence interval length.
- Moreover, the larger the sample size, the more precise the conclusion, for the same confidence level.
- Therefore, .purple[every decision based on statistical methods has a risk and how much risk is acceptable depends on the context] (e.g. safety in airplanes vs which soft drink tastes better).
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
