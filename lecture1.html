<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Statistics</title>
    <meta charset="utf-8" />
    <meta name="author" content="St√©phane Guerrier &amp; Yuming Zhang" />
    <meta name="date" content="2020-12-18" />
    <link href="lecture1_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="lecture1_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="lecture1_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link href="lecture1_files/tile-view-0.2.4/tile-view.css" rel="stylesheet" />
    <script src="lecture1_files/tile-view-0.2.4/tile-view.js"></script>
    <link href="lecture1_files/panelset-0.2.4/panelset.css" rel="stylesheet" />
    <script src="lecture1_files/panelset-0.2.4/panelset.js"></script>
    <script src="lecture1_files/clipboard-2.0.6/clipboard.min.js"></script>
    <link href="lecture1_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="lecture1_files/xaringanExtra-clipboard-0.2.4/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to Statistics
## Part I: Introduction to Statistical Inference
### St√©phane Guerrier &amp; Yuming Zhang
### 18 December 2020

---









# Introduction

Welcome to the class ".hi-purple[Introduction to Statistics]"!

Throughout this class, we will use a platform called .hi-pink[Piazza] for the share of all the teaching materials and Q&amp;A. 

&lt;img src="pics/piazza.png" width="40%" style="display: block; margin: auto;" /&gt;

- Signup Link: [https://piazza.com/configure-classes/winter2020/sisu](https://piazza.com/configure-classes/winter2020/sisu)
- Access Code: .purple[statisfun]

---

# R and RStudio

.pull-left[
In this class, we will use the statistical software .hi-pink[R] together with the integrated development environment .hi-pink[R Studio], which can be downloaded with the following: 

- Latest version of R: [https://cran.r-project.org/](https://cran.r-project.org/)
- Latest version of R Studio: [https://www.rstudio.com/](https://www.rstudio.com/)

.hi-purple[Note:] You cannot use RStudio without having installed R on your computer.
]

.pull-right[

&lt;img src="pics/r_first_then.png" width="100%" style="display: block; margin: auto;" /&gt;

]

---

# What is statistics?

.pull-left[
.smaller[.hi-pink[Statistics] is a science that uses mathematics and computer science to deal with the collection, analysis, interpretation, and presentation of masses of numerical data. Informally, it is the .pink[science of learning from data].]
&lt;img src="pics/stat.jpeg" width="90%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [luminousmen](luminousmen.com)]
]

.pull-right[
.smaller[.hi-purple[Statistics] is a crucial part of our life. However, .purple[statistical methods are often consciously (or not) misused]. This can lead to contradictory studies and conclusions (as seen during the current COVID-19 pandemic).]

&lt;img src="pics/data-torture.png" width="80%" style="display: block; margin: auto;" /&gt;

.tiny[Source: [Atoz Markets](https://atozmarkets.com/news/untold-reality-of-p-hacking-in-finance/)]
]

---

# How can statistics be useful?

.smallest[Statistics can be used (among others) to

1. .purple[Visualize data] (e.g. propagation of COVID-19 in different countries).
2. .purple[Understand and interpret data] (e.g. main causes of cancer). 
3. .purple[Assess the validity of a hypothesis] (e.g. is a drug working?).
4. .purple[Make predictions] (e.g. predicting unemployment or risk indices).]

.smallest[Learning more about statistics allows to 

1. Better understand .pink[arguments based on data.]
2. Be able to apply .pink[critical thinking] about .pink[statistics used as evidence].
3. Understand how statistical associations are used to .pink[evaluate claims (hypotheses)] and .pink[assess causal connections.]] 

.smallest[.purple[Understanding and knowing how to interpret statistical analyses is therefore becoming an increasingly vital skill.]]

---

# Simpson's Paradox

.pull-left[.smallest[.hi-pink[Statistical analysis can be tricky.] Here we give an example of a study of gender bias among graduate school admissions to University of California, Berkeley, for the fall of 1973.]

&lt;img src="lecture1_files/figure-html/unnamed-chunk-4-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
.smallest[
The data show that .purple[among 8,442 men applicants 44% were admitted] while .pink[among 4,321 women applicants only 35% were admitted]. The overall admission rate was around 41%. The difference is quite large (9%) and it is a large sample with 12,763 applicants, so it is unlikely that this is due to chance. Therefore, the data suggest that .purple[men applying were more likely to be admitted than women].

However, when people looked more into the data, they found that this conclusion is actually completely incorrect. In fact, a correct analysis showed that .pink["small but statisticall significant bias in favor of women"]. But why? üòÆ
]
]

---

# Simpson's Paradox

.pull-left[

&lt;img src="lecture1_files/figure-html/unnamed-chunk-5-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="lecture1_files/figure-html/unnamed-chunk-6-1.svg" width="100%" style="display: block; margin: auto;" /&gt;

]

- .smallest[Men applicants tended to apply for "easy" departments, i.e. departments that had high admission rates.] 
- .smallest[Women applicants tended to apply to "hard" departments, i.e. departments that had low admission rates.]  
- .smallest[So it turns out that most of the departments actually had a slightly higher success rate for women.]
- .smallest[This phenomenon is actually very common and known as .hi-purple[Simpson's Paradox]. ]

---

# How does it work?

.smallest[
- Statistical methods are based on several fundamental concepts, the most central of which is to consider the information available (in the form of data) resulting from a .purple[random process].
- As such, the data represent a .hi-pink[random sample] of a totally or conceptually accessible .hi-pink[population].
- Then, .purple[statistical inference] allows to infer the properties of a population based on the observed sample. This includes deriving estimates and testing hypotheses.
]

&lt;img src="pics/sampling.png" width="45%" style="display: block; margin: auto;" /&gt;
.tiny[Source: [luminousmen](luminousmen.com)]


---

# Outline

In this class, we plan to cover the following topics: 

- Introduction to .pink[statistical inference] (concepts of random variables, confidence interval and p-values).
- Introduction to the .purple[statistical software R].
- .pink[Tests for comparing the mean of two groups] (descriptive analysis, t-test, rank-based methods).
- .purple[Tests for comparing the mean of multiple groups] (descriptive analysis, ANOVA and non-parametric counterparts, discussion on multiple testing).
- Introduction to .pink[regression] (correlation vs causality, descriptive analysis, linear regression and going beyond linear regression).
- .purple[Pitfalls] for statistical analysis and remedies (p-hacking/HARKing and how to avoid it, replicability crisis).

---

# Population and Sample - Example

.smallest[To fix ideas we will consider a simple example. The 2020 United States presidential election was the 59th quadrennial presidential election, held on November 3, 2020. According to the latest estimates, .hi.pink[Biden's team received 51.3% of the votes while Trump's received 46.8%] &lt;sup&gt;.smallest[üëã]&lt;/sup&gt;. Naturally, the result of American elections is not determined by the popular vote but suppose that we were interested in collecting data .hi-purple[before the vote] to assess if Biden's team will receive more than 50% of the votes].

&lt;img src="pics/trump2.png" width="80%" style="display: block; margin: auto;" /&gt;

.tiny[Source: Adapted from [fivethirtyeight.](https://projects.fivethirtyeight.com/trump-biden-election-map/)]

.footnote[.smallest[üëã More details on the results can be found [here](https://en.wikipedia.org/wiki/2020_United_States_presidential_election).]]

---

# Population and Sample - Example

.pull-left[.smaller[In this example, we will make the .purple[following assumptions for simplicity]:

- The American population of voters is composed of 1200 individuals (616 for Biden, 561 for Trump and 23 independents).
- We can perfectly sample the population (everyone is available, no double sampling, and the sampling is random).
- People don't change their mind and they don't lie.
]]

.pull-right[

&lt;img src="pics/pop.jpg" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Proportion Estimation

Suppose we ask `\(n\)` voters for which candidate (Biden, Trump or independent) they intend to vote in order to estimate the proportion of voters for Biden. For that we define the .hi.purple[random variables] `\(X_1, ..., X_n\)` where `\(X_i\)` is defined as:

.saller[
.center[
`\(
X_i = \left\{
	\begin{array}{ll}
		1  &amp; \mbox{if voter } i \mbox{ intends to vote for Biden}\\
		0 &amp; \mbox{otherwise.}
	\end{array}
\right.
\)`
]
]


The random variables `\(X_1, ..., X_n\)` are called a (random) .hi.purple[sample] and we refer to `\(n\)` as the .hi.purple[sample size]. Let `\(p\)` denote the (true) proportion of voters for Biden (which in this case is 51.3%), we then write


$$
`\begin{align}
\color{#e64173}{\Pr \Big(} {X_i = 1} \color{#e64173}{\Big)} = p,
\end{align}`
$$


where `\(\color{#e64173}{\Pr (} A \color{#e64173}{)}\)` denotes the .pink[probability] of the .purple[event] `\(A\)`.

---

# Proportion Estimation

Using the random variables `\(X_1, ..., X_n\)` we can define an .hi.purple[estimator] of `\(p\)`, which we often write as `\(\hat{p}\)` and is given by


`$$\hat{p} = \frac{1}{n} \sum_{i=1}^n X_i = \frac{\color{#e64173}{m}}{\color{#6A5ACD}{n}},$$`


where `\(\color{#e64173}{m}\)` denotes the number of voters in our sample in favor of Biden, and `\(\color{#6A5ACD}{n}\)` is the sample size (as described previously).

An estimator is defined as a function of the data (i.e. `\(X_1, ..., X_n\)`), and therefore, theoretically any function of `\(X_1, ..., X_n\)` can be an estimator. However, in this case `\(\hat{p}\)` is the best possible estimator of `\(p\)` &lt;sup&gt;.smallest[üëã]&lt;/sup&gt; and therefore it is not useful (in this case) to search for better estimators.

.footnote[.smallest[üëã] More precisely, this estimator is unbiased [(more info.)](https://en.wikipedia.org/wiki/Bias_of_an_estimator) and has the smallest possible variance [(more info.)](https://en.wikipedia.org/wiki/Variance) as it attains the Cram√©r‚ÄìRao bound [(more info.)](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound).]
 
---

# Population and Sample - Example

.pull-left[
.smallest[
Consider a sample of `\(n = 10\)` voters (randomly chosen from the population) as shown here üëâ. In this case, we have 5 voters for Biden and 5 for Trump. We say that `$$x_1 = 1, ..., x_5 = 1, x_6 = 0, ..., x_{10} = 0$$` are .hi.purple[realizations] of the random variables `\(X_1, ..., X_{10}\)`.

We can now compute our estimator on the observed data (i.e. the realizations) and we obtain `\(\hat{p} = 0.5\)`. Therefore, .pink[our best guess] based on the available data is that 50% of the voters will vote for Biden. Unfortunately, this doesn't really help us. So let's try with a bigger sample size... say `\(n = 40\)`.
]]

.pull-right[

&lt;img src="pics/sample1.jpg" width="90%" style="display: block; margin: auto;" /&gt;

]

---

# Population and Sample - Example

&lt;img src="pics/sample3.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Population and Sample - Example

.center[![](GIF/sample.gif)]

---

# Population and Sample - Example

&lt;img src="pics/sample_n2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Population and Sample - Example

&lt;img src="pics/sample_n.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---

# Population and Sample - Example

- In our example, we are interested in knowing if `\(p\)`, a .pink[population-level quantity], is bigger or smaller than 50%. Unfortunately, `\(p\)` is generally unknown as we cannot access the whole population (otherwise let's not bother with Statistics! ü§™). Therefore, we use `\(\hat{p}\)` instead, a .purple[sample-dependent quantity].
- However, as we can see, `\(\hat{p}\)` is .turquoise[random] in the sense that it can change depending on the collected sample (e.g. we get different answers when `\(n = 200\)`, where Trump is leading, and when `\(n = 600\)`, where Biden is leading). 
- To address this issue, we need to assess the .hi.pink[uncertainty] of `\(\hat{p}\)` (i.e. assess how different `\(\hat{p}\)` and `\(p\)` can be).
- Statistics can provides us many tools allowing to determine uncertainty as well as the associated .pink[decision-making risks].

---

# How to measure uncertainty?

Uncertainty can be measured in many different ways. A common approach (in statistics) is to use .hi-purple[confidence intervals], which rely on the .hi.pink[Central Limit Theorem (CLT)] that states:

.center[.turquoise["The sampling distribution of the sample mean approaches to a normal distribution as the sample size gets larger."]]

Loosely speaking, we can translate the CLT as 

`$$\bar{X} = \frac{1}{n} \sum_{i = 1}^n X_i \color{#e64173}{\overset{\cdot}{\sim}} \color{#6A5ACD}{\mathcal{N}(\mu, \sigma^2)},$$` 

where `\(\color{#6A5ACD}{\mathcal{N}(\mu, \sigma^2)}\)` denotes a normal distribution with mean `\(\mu\)` and variance `\(\sigma^2\)` (typically computed using the data)&lt;sup&gt;.smallest[üëã]&lt;/sup&gt;. Here `\(\bar{X}\)` denotes the sample mean and `\(\color{#e64173}{\overset{\cdot}{\sim}}\)` represents ".pink[approximately distributed as]". 

.footnote[.smallest[üëã] Check out [expected value](https://en.wikipedia.org/wiki/Expected_value) and [variance](https://en.wikipedia.org/wiki/Variance).]

---

# How to measure uncertainty?

In our example, we have 

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(p, \frac{p(1-p)}{n}\Bigg).$$`
.pink[How to understand the practical implications of the CLT?] Informally, it means that when a measurement can be thought of as the sum (or the average) of .hi.purple[numerous] factors, its distribution tends to go to a normal distribution. For example, the height of adults can be thought of as the sum of their genetic information, diet, life style, ...

---

# Distribution of heights

&lt;img src="pics/distribution-1.png" width="90%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt1.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt3.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

.center[![](GIF/sample_clt.gif)]

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt_n.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

.center[![](GIF/sample_clt2.gif)]

---

# Central Limit Theorem - Example

&lt;img src="pics/sample_clt_n2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Central Limit Theorem - Example

People have used .pink[the Galton Board] as a practical device to demonstrate the CLT, in particular that with sufficient sample size the binomial distribution approximates a normal distribution.

&lt;div align="center"&gt;
&lt;iframe width="684" height="381" src="https://www.youtube.com/embed/Vo9Esp1yaC8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;

---

# Confidence Intervals

Now that we learn about CLT, how can we use it to construct .hi-purple[confidence intervals]? 

- .smaller[Confidence intervals correspond to .pink[a range of values that are likely to include the population value with a certain level of confidence]. The level of confidence is a probability expressed as a percentage (%).] 
- .smaller[In our example, we are interested in the true (population) proportion of voters in favor of Biden (51.3%). Using our sample of] `\(\small n=200\)` .smaller[, we had] `\(\small m =95\)` .smaller[and we can construct the following 95% confidence interval]:

.pull-left[
&lt;img src="pics/ci.jpg" width="90%" style="display: block; margin: auto;" /&gt;
]

.smaller[.pull-right[
So what does it mean? ü§î It means that with a .hi-purple[probability of 95%], the true proportion of voters for Biden (51.3% in this case) is between 40.58% and 54.42%.]
]


---

# Confidence Intervals

How is this confidence interval computed? We recall that by CLT, 

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(p, \frac{p(1-p)}{n}\Bigg).$$`
However, as we .hi.purple[do not know] the true value of `\(p\)` in practice, we replace it with the .hi.purple[best guess] we have, which is `\(\hat{p}\)`. We then can write

`$$\hat{p} \overset{\cdot}{\sim} \mathcal{N}\Bigg(\color{#e64173}{\hat{p}}, \color{#6A5ACD}{\frac{\hat{p}(1-\hat{p})}{n}}\Bigg).$$`

The `\(1-\alpha\)` confidence interval for `\(p\)` is then given by

`$$\color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}}.$$`

But what is `\(Z_{1-\alpha/2}\)`? ü§ì

---

# Confidence Intervals

`\(Z_{1-\alpha/2}\)` corresponds to the `\(1-\alpha/2\)` quantile of a standard normal distribution `\(\mathcal{N}(0,1)\)`, that is, 

.center[ 
`\(Z_{1-\alpha/2}\)` is such that `\(\Pr(Z \leq Z_{1-\alpha/2}) = 1-\alpha/2\)` where `\(Z \sim \mathcal{N}(0,1)\)`.
]

.pull-left[

&lt;img src="pics/standard_normal.png" width="70%" style="display: block; margin: auto;" /&gt;

]

.pull-right[
- For 90% confidence interval, `\(Z_{0.95} \approx 1.64\)`. 
- .pink[For 95% confidence interval,] `\(\color{#e64173}{Z_{0.975} \approx 1.96}\)`.pink[.]
- For 99% confidence interval, `\(Z_{0.995} \approx 2.58\)`. 
]
---

# Confidence Intervals

Therefore, a confidence interval corresponds to a range of values that contains the true unknown population-level quantity we are considering with a probability of approximately `\(1-\alpha\)` (typically 95%).

Basically, we have

`$$\Pr \left(p \in \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \right) \approx 1-\alpha.$$`

‚ö†Ô∏è This means that a fraction of `\(100\times\alpha\)`% of confidence intervals .hi.pink[don't include] `\(p\)`. 

---

# Confidence Intervals

.center[![](GIF/sample_clt3.gif)]

---

# Confidence Intervals

&lt;img src="pics/ci2.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

# How to compute confidence intervals

.panelset[
.panel[.panel-name[Example]
.smallest[Previously, we said that in a sample of] `\(\small n=200\)`.smallest[, we had] `\(\small m = 95\)`.smallest[. In this case, we mentioned that (40.58%, 54.42%) was a 95% confidence interval. But how are these numbers computed? We have]

$$ \small \color{#e64173}{\hat{p}} = \frac{m}{n} = \frac{95}{200} = \color{#e64173}{47.5\%}.$$
.smallest[Then, we have]

`$$\small\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#6A5ACD}{0.0353}.$$`
.smallest[To obtain a 95% confidence interval we used] `\(\small Z_{1-\alpha/2} = Z_{0.975} \approx 1.96\)` .smallest[ and we get]

`$$\small \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#e64173}{\frac{51.728}{100}} \pm 1.96 \times \color{#6A5ACD}{0.0353} = (40.58\%, 54.42\%).$$`

]
.panel[.panel-name[`R` Code - üí™]

```r
n = 200                    # Sample size
m = 95                     # Number of boys
alpha = 0.05               # Confidence level (1-alpha)
p_hat = m/n                # Estimated proportion

# Compute CI
Z = qnorm(1 - alpha/2)
delta = sqrt(p_hat*(1 - p_hat)/n)
CI = p_hat + c(-1, +1)*Z*delta
print(paste("The estimated proportion is ", round(100*p_hat, 2), "%", sep = ""))
```

```
#&gt; [1] "The estimated proportion is 47.5%"
```

```r
print(paste("A ", (1 - alpha)*100, "% confidence interval is given by (",
            round(100*CI[1], 2), "%, ", round(100*CI[2], 2), "%)", sep = ""))
```

```
#&gt; [1] "A 95% confidence interval is given by (40.58%, 54.42%)"
```
]
]

---

# Confidence Interval with `\(\alpha = 20\%\)`

&lt;img src="pics/sample_ci_trump1.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Confidence Interval with `\(\alpha = 20\%\)`

&lt;img src="pics/sample_ci_trump2.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Confidence Interval with `\(\alpha = 20\%\)`

&lt;img src="pics/sample_ci_trump3.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---

# Confidence Intervals with `\(\alpha = 20\%\)`

.center[![](GIF/sample_ci.gif)]

---

# Why is 20%? Why not 5%?

.center[![](GIF/sample_ci5.gif)]

---

# What if I want to be certain? üò≥

.center[![](GIF/sample_ci0.gif)]

---


# ‚ö†Ô∏è Take home message

- Since the data is available through sampling, it is .hi-purple[random]. .pink[Therefore, a decision or prediction can never be made with certainty!]
- The only certainty one can have is that, for example, a proportion will always be included in the interval from 0% to 100%. .hi-purple[However, this is neither informative nor useful] and it does not even depend on the data.
- There exists a trade-off between .hi-pink[risk] as measured by  `\(1-\alpha\)` (typically 95%) the confidence level, and the .hi-pink[precision of the conclusion] as measured, for example, by the confidence interval length.
- Moreover, the larger the sample size, the more precise the conclusion, for the same confidence level.
- Therefore, .purple[every decision based on statistical methods has a risk and how much risk is acceptable depends on the context] (e.g. safety in airplanes vs which soft drink tastes better).

---

# Example: Are there more üë¶ than üëß?

.panelset[
.panel[.panel-name[Problem]
.smallest[An American found 13,173 boys were born among 25,468 newborn children. Is this sample an evidence that the birth of boys may be more common than the birth of girls in the entire population?] .smallest[So, we have] `\(\small n = 25,468\)` .smallest[and] `\(\small m = 13,173\)`. .smallest[Therefore, we have]

$$ \small \color{#e64173}{\hat{p}} = \frac{m}{n} = \frac{13173}{25468} \approx \color{#e64173}{51.728\%}.$$
.smallest[Then, we have]

`$$\small\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#6A5ACD}{0.003131}.$$`
.smallest[To obtain a 95\% confidence interval we used] `\(\small Z_{1-\alpha/2} = Z_{0.975} \approx 1.96\)` .smallest[ and we get]

`$$\small \color{#e64173}{\hat{p}} \pm Z_{1-\alpha/2}\color{#6A5ACD}{\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}} \approx \color{#e64173}{\frac{51.728}{100}} \pm 1.96 \times \color{#6A5ACD}{0.003131} = (51.11\%, 52.34\%).$$`

]
.panel[.panel-name[`R` Code - üí™]

```r
n = 25468                  # Sample size
m = 13173                  # Number of boys
alpha = 0.05               # Confidence level (1-alpha)
p_hat = m/n                # Estimated proportion

# Compute CI
Z = qnorm(1 - alpha/2)
delta = sqrt(p_hat*(1 - p_hat)/n)
CI = p_hat + c(-1, +1)*Z*delta
print(paste("The estimated proportion is ", round(100*p_hat, 2), "%", sep = ""))
```

```
#&gt; [1] "The estimated proportion is 51.72%"
```

```r
print(paste("A ", (1 - alpha)*100, "% confidence interval is given by (",
            round(100*CI[1], 2), "%, ", round(100*CI[2], 2), "%)", sep = ""))
```

```
#&gt; [1] "A 95% confidence interval is given by (51.11%, 52.34%)"
```
]

.panel[.panel-name[`R` Code - ü§ñ]


```r
n = 25468                  # Sample size
m = 13173                  # Number of boys
prop.test(x = m, n = n)
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  m out of n, null probability 0.5
#&gt; X-squared = 30.2, df = 1, p-value = 3.897e-08
#&gt; alternative hypothesis: true p is not equal to 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.5110785 0.5233910
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5172373
```
]
]

---

# How to test a (scientific) hypothesis?

- .smallest[An alternative summary measure of uncertainty is provided  by .hi-pink[p-values] that take values between 0% and 100%.]
- .smallest[However, .hi-purple[p-values have been misused] many times because understanding what they mean is not intuitive.]

&lt;div align="center"&gt;
&lt;iframe src="https://fivethirtyeight.abcnews.go.com/video/embed/56150342" width="512" height="288" scrolling="no" style="border:none;" allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt; 

üëã .tiny[If you want to know more have a look [here](https://fivethirtyeight.com/features/statisticians-found-one-thing-they-can-agree-on-its-time-to-stop-misusing-p-values/).]

---

# How to test a (scientific) hypothesis?

- .smaller[A p-value is associated to a (couple of) .purple[hypotheses] about the phenomenon under investigation.
A hypothesis testing is designed to assess the strength of evidence against a baseline hypothesis that is called .pink[null hypothesis] `\(\color{#e64173}{H_0}\)` and in favor of another hypothesis that is called .pink[alternative hypothesis] `\(\color{#e64173}{H_a}\)`.] 
- In the Biden-Trump example, we can write
.center[
`\(H_0: p = 0.5\)` and `\(H_a: p &gt; 0.5\)`.
]
- .smaller[Each hypothesis .purple[excludes the other], so that one can .purple[exclude one in favor of the other] using the data.]
- .smaller[The .pink[null hypothesis] is the one that one will never be able to prove because the data is random.]
- .smaller[The .pink[alternative hypothesis] is the one that offers more choice of values and hence has a chance to be favored with respect to the null hypothesis.]

---

# Testing

- .smallest[Informally, .hi-pink[a p-value can be understood as a measure of plausibility of the null hypothesis given the data]. The smaller the p-value the greater the incompatibility of the null hypothesis with the data.]
- .smallest[When the p-value is small enough (typically smaller than 5%), one says that the test based on the null and alternative hypotheses is .hi-pink[significant] or that the null hypothesis is rejected in favor of the alternative. .purple[This is generally what we want because it "verifies" our (research) hypothesis].]
- .smallest[When the p-value is not small enough (typically larger than 5%), with the available data, we cannot reject the null hypothesis and then .hi-pink[nothing] can be concluded. ü§î]
- .smallest[With a sample of data, the obtained p-value (associated to a couple of hypotheses) summarizes somehow the .hi-pink[incompatibility between the data and the model] (random process) constructed under the set of assumptions.]
- .smallest[The p-value is usually compared to a .purple[threshold value] that sets the (subjective) risk level of decision in favor of the incompatibility. The risk level is called the .purple[significance level] and is a small value, usually 5%, but this depends on the context.]

---

# Example: Biden-Trump

.panelset[
.panel[.panel-name[Problem]
.smallest[Returning to our Biden-Trump example, suppose we believe (or hope to show that) .pink[Biden will have more than 50% of the votes]. We collect data with] `\(\small n = 600\)` .smallest[and] `\(\small m = 322\)`.smallest[. We will consider the following steps to set up the test:]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.5\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&gt;} 0.5\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 3.959\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &lt;] `\(\small \alpha\)` .smallest[so we can reject the null hypothesis and conclude that the proportion of voters for Biden is greater than 50%.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 322, n = 600, p = 0.5, alternative = "greater")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  322 out of 600, null probability 0.5
#&gt; X-squared = 3.0817, df = 1, p-value = 0.03959
#&gt; alternative hypothesis: true p is greater than 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.5022582 1.0000000
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5366667
```
]
]

---

# Example: Biden-Trump

.panelset[
.panel[.panel-name[Problem]
.smallest[What if we want to check if .pink[Trump will have more than 50% of the votes]. Using the same data, we set up the test as follows:]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.5\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&lt;} 0.5\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 96.04\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that Trump will have more than 50% of the votes.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 322, n = 600, p = 0.5, alternative = "less")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  322 out of 600, null probability 0.5
#&gt; X-squared = 3.0817, df = 1, p-value = 0.9604
#&gt; alternative hypothesis: true p is less than 0.5
#&gt; 95 percent confidence interval:
#&gt;  0.0000000 0.5707377
#&gt; sample estimates:
#&gt;         p 
#&gt; 0.5366667
```
]
]

---

# Example: Breastfeeding and income
.panelset[
.panel[.panel-name[Problem]
.smallest[A researcher who is studying the effects of income levels on breastfeeding of infants hypothesizes that countries where the income level is lower have a higher rate of infant breastfeeding than higher income countries. It is .hi.purple[known] that in Germany (high-income country), 22% of all babies are breastfeed. In Tajikistan (low-income country) researchers found that in a random sample of 500 new mothers that 125 were breastfeeding their infants. What can we conclude?]
1. .smallest[.purple[Define hypotheses:]] `\(\small H_0: p = 0.22\)` .smallest[and] `\(\small H_a: p \color{#e64173}{&gt;} 0.22\)`.
2. .smallest[.purple[Define]] `\(\small \color{#6A5ACD}{\alpha}\)`.smallest[: We consider] `\(\small \alpha = 5\%\)`.smallest[.]
3. .smallest[.purple[Compute p-value]: p-value = ] `\(\small 5.874\%\)` .smallest[(see computation tab for details).]
4. .smallest[.purple[Conclusion:] We have p-value &gt;] `\(\small \alpha\)` .smallest[and we cannot reject the null hypothesis. We don't have enough evidence to conclude that countries where the income level is lower have a higher rate of infant breastfeeding than higher income countries.]
]
.panel[.panel-name[`R` Code ]

```r
prop.test(x = 125, n = 500, p = 0.22, alternative = "greater")
```

```
#&gt; 
#&gt; 	1-sample proportions test with continuity correction
#&gt; 
#&gt; data:  125 out of 500, null probability 0.22
#&gt; X-squared = 2.4505, df = 1, p-value = 0.05874
#&gt; alternative hypothesis: true p is greater than 0.22
#&gt; 95 percent confidence interval:
#&gt;  0.218598 1.000000
#&gt; sample estimates:
#&gt;    p 
#&gt; 0.25
```
]
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
